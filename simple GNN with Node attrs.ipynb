{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import timeit\n",
    "import statistics\n",
    "import time\n",
    "import torch\n",
    "import torch_geometric\n",
    "import importlib\n",
    "\n",
    "from data_utils import synthetic_data\n",
    "from data_utils import graph_constructors\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data_utils.graph_constructors' from 'C:\\\\Users\\\\andy.knapper\\\\Documents\\\\OW\\\\Categorisation\\\\ML grouping\\\\GNN-for-trans-grouping\\\\data_utils\\\\graph_constructors.py'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(synthetic_data)\n",
    "importlib.reload(graph_constructors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit synthetic_data.make_a_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colour_list = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan']\n",
    "\n",
    "for i in range(2):\n",
    "    d_lst, a_lst, g_lst, t_lst = synthetic_data.make_a_group()\n",
    "    \n",
    "    d_arr = np.array(d_lst)\n",
    "    a_arr = np.array(a_lst)\n",
    "    g_arr = np.array(g_lst)    \n",
    "    \n",
    "    fig, (ax1) = plt.subplots(nrows=1, ncols=1, figsize=(10,8), sharex=True)\n",
    "    for g in g_lst:\n",
    "        mask = (g_arr == g)\n",
    "        \n",
    "        ax1.scatter(d_arr[mask], a_arr[mask], s=10, c=colour_list[g%10], marker='x')\n",
    "        ax1.set_title(str(i))\n",
    "        #ax1.legend(loc=\"upper right\")\n",
    "    \n",
    "    for ax1 in fig.axes:\n",
    "        matplotlib.pyplot.sca(ax1)\n",
    "        plt.xticks(rotation=90)\n",
    "        #plt.legend(bbox_to_anchor=(1.02, 1), loc=2, borderaxespad=0.)\n",
    "    \n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_lst, a_lst, g_lst, t_lst = synthetic_data.make_a_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_arr = np.array(d_lst)\n",
    "a_arr = np.array(a_lst)\n",
    "g_arr = np.array(g_lst)\n",
    "t_arr = np.array(t_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_a_arr = graph_constructors.normalise_amounts(a_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = graph_constructors.make_pyg_graph_no_edge_attr(d_arr, a_arr, g_arr, t_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([52, 14])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([52])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_ids = [x for x in range(len(d_arr))]\n",
    "positions_list = [(x[0], x[1]) for x in data['pos'].tolist()]\n",
    "pos_dict = dict(zip(node_ids, positions_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch_geometric.utils.to_networkx(data, node_attrs=None, edge_attrs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andy.knapper\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\networkx\\drawing\\nx_pylab.py:579: MatplotlibDeprecationWarning: \n",
      "The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead.\n",
      "  if not cb.iterable(width):\n",
      "C:\\Users\\andy.knapper\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\networkx\\drawing\\nx_pylab.py:676: MatplotlibDeprecationWarning: \n",
      "The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead.\n",
      "  if cb.iterable(node_size):  # many node sizes\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15, 15))\n",
    "nx.draw_networkx(g, ax=ax, node_size=5,\n",
    "                 font_size=6, alpha=.5,\n",
    "                 width=.5, pos = pos_dict)\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try a simple model first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #from torch.utils.data import Dataset, DataLoader\n",
    "# from torch_geometric.data import Data, DataLoader\n",
    "# from torchvision import transforms, datasets, models\n",
    "\n",
    "# class SimDataset(Dataset):\n",
    "#     def __init__(self, count):\n",
    "#         self.sim_data = [graph_constructors.make_pyg_graph_no_edge_attr(*np.array(synthetic_data.make_a_group())) for _ in range(count)]\n",
    "#         self.input_graphs = [(g.x, g.edge_index) for  g in self.sim_data]\n",
    "#         self.targets = [g.y for g in self.sim_data]#.astype('float32')\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.input_graphs)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         graph = self.input_graphs[idx]\n",
    "#         target = self.targets[idx]\n",
    "#         return [graph, target]\n",
    "\n",
    "\n",
    "# train_set = SimDataset(2000)\n",
    "# val_set = SimDataset(200)\n",
    "\n",
    "# graph_datasets = {\n",
    "#     'train': train_set, 'val': val_set\n",
    "# }\n",
    "\n",
    "# batch_size = 4\n",
    "\n",
    "# dataloaders = {\n",
    "#     'train': DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0),\n",
    "#     'val': DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data, DataLoader\n",
    "\n",
    "train_data_list = [graph_constructors.make_pyg_graph_no_edge_attr(*np.array(synthetic_data.make_a_group())).to(device) for _ in range(2000)]\n",
    "val_data_list = [graph_constructors.make_pyg_graph_no_edge_attr(*np.array(synthetic_data.make_a_group())).to(device) for _ in range(200)]\n",
    "\n",
    "train_loader = DataLoader(train_data_list, batch_size=8)\n",
    "val_loader = DataLoader(val_data_list, batch_size=8)\n",
    "\n",
    "dataloaders = {\n",
    "    'train': train_loader,\n",
    "    'val': val_loader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential, Linear, ReLU\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.nn import GINConv, global_add_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GINConv, global_add_pool, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_sparse import spspmm\n",
    "from torch_geometric.nn import TopKPooling, GCNConv\n",
    "from torch_geometric.utils import (add_self_loops, sort_edge_index,\n",
    "                                   remove_self_loops)\n",
    "from torch_geometric.utils.repeat import repeat\n",
    "\n",
    "\n",
    "class GraphUNet(torch.nn.Module):\n",
    "    r\"\"\"The Graph U-Net model from the `\"Graph U-Nets\"\n",
    "    <https://arxiv.org/abs/1905.05178>`_ paper which implements a U-Net like\n",
    "    architecture with graph pooling and unpooling operations.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Size of each input sample.\n",
    "        hidden_channels (int): Size of each hidden sample.\n",
    "        out_channels (int): Size of each output sample.\n",
    "        depth (int): The depth of the U-Net architecture.\n",
    "        pool_ratios (float or [float], optional): Graph pooling ratio for each\n",
    "            depth. (default: :obj:`0.5`)\n",
    "        sum_res (bool, optional): If set to :obj:`False`, will use\n",
    "            concatenation for integration of skip connections instead\n",
    "            summation. (default: :obj:`True`)\n",
    "        act (torch.nn.functional, optional): The nonlinearity to use.\n",
    "            (default: :obj:`torch.nn.functional.relu`)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, depth,\n",
    "                 pool_ratios=0.5, sum_res=True, act=F.relu):\n",
    "        super(GraphUNet, self).__init__()\n",
    "        assert depth >= 1\n",
    "        self.in_channels = in_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.depth = depth\n",
    "        self.pool_ratios = repeat(pool_ratios, depth)\n",
    "        self.act = act\n",
    "        self.sum_res = sum_res\n",
    "\n",
    "        channels = hidden_channels\n",
    "\n",
    "        self.down_convs = torch.nn.ModuleList()\n",
    "        self.pools = torch.nn.ModuleList()\n",
    "        self.down_convs.append(GCNConv(in_channels, channels, improved=True))\n",
    "        for i in range(depth):\n",
    "            self.pools.append(TopKPooling(channels, self.pool_ratios[i]))\n",
    "            self.down_convs.append(GCNConv(channels, channels, improved=True))\n",
    "\n",
    "        in_channels = channels if sum_res else 2 * channels\n",
    "\n",
    "        self.up_convs = torch.nn.ModuleList()\n",
    "        for i in range(depth - 1):\n",
    "            self.up_convs.append(GCNConv(in_channels, channels, improved=True))\n",
    "        self.up_convs.append(GCNConv(in_channels, out_channels, improved=True))\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.down_convs:\n",
    "            conv.reset_parameters()\n",
    "        for pool in self.pools:\n",
    "            pool.reset_parameters()\n",
    "        for conv in self.up_convs:\n",
    "            conv.reset_parameters()\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, batch=None):\n",
    "        \"\"\"\"\"\"\n",
    "        if batch is None:\n",
    "            batch = edge_index.new_zeros(x.size(0))\n",
    "        edge_weight = x.new_ones(edge_index.size(1))\n",
    "\n",
    "        x = self.down_convs[0](x, edge_index, edge_weight)\n",
    "        x = self.act(x)\n",
    "\n",
    "        xs = [x]\n",
    "        edge_indices = [edge_index]\n",
    "        edge_weights = [edge_weight]\n",
    "        perms = []\n",
    "\n",
    "        for i in range(1, self.depth + 1):\n",
    "            edge_index, edge_weight = self.augment_adj(edge_index, edge_weight,\n",
    "                                                       x.size(0))\n",
    "            x, edge_index, edge_weight, batch, perm, _ = self.pools[i - 1](\n",
    "                x, edge_index, edge_weight, batch)\n",
    "\n",
    "            x = self.down_convs[i](x, edge_index, edge_weight)\n",
    "            x = self.act(x)\n",
    "\n",
    "            if i < self.depth:\n",
    "                xs += [x]\n",
    "                edge_indices += [edge_index]\n",
    "                edge_weights += [edge_weight]\n",
    "            perms += [perm]\n",
    "\n",
    "        for i in range(self.depth):\n",
    "            j = self.depth - 1 - i\n",
    "\n",
    "            res = xs[j]\n",
    "            edge_index = edge_indices[j]\n",
    "            edge_weight = edge_weights[j]\n",
    "            perm = perms[j]\n",
    "\n",
    "            up = torch.zeros_like(res)\n",
    "            up[perm] = x\n",
    "            x = res + up if self.sum_res else torch.cat((res, up), dim=-1)\n",
    "\n",
    "            x = self.up_convs[i](x, edge_index, edge_weight)\n",
    "            x = self.act(x) if i < self.depth - 1 else x\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "    def augment_adj(self, edge_index, edge_weight, num_nodes):\n",
    "        edge_index, edge_weight = add_self_loops(edge_index, edge_weight,\n",
    "                                                 num_nodes=num_nodes)\n",
    "        edge_index, edge_weight = sort_edge_index(edge_index, edge_weight,\n",
    "                                                  num_nodes)\n",
    "        edge_index, edge_weight = spspmm(edge_index, edge_weight, edge_index,\n",
    "                                         edge_weight, num_nodes, num_nodes,\n",
    "                                         num_nodes)\n",
    "        edge_index, edge_weight = remove_self_loops(edge_index, edge_weight)\n",
    "        return edge_index, edge_weight\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}({}, {}, {}, depth={}, pool_ratios={})'.format(\n",
    "            self.__class__.__name__, self.in_channels, self.hidden_channels,\n",
    "            self.out_channels, self.depth, self.pool_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = [graph_constructors.make_pyg_graph_no_edge_attr(*np.array(synthetic_data.make_a_group())).to(device) for _ in range(32)]\n",
    "# loader = DataLoader(dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphUNet(in_channels = 14, hidden_channels = 5, out_channels = 1, depth = 3)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(pred, target, smooth = 1.):\n",
    "    pred = pred.contiguous()\n",
    "    target = target.contiguous()\n",
    "\n",
    "    intersection = (pred * target)\n",
    "    \n",
    "    loss = (1 - ((2. * intersection + smooth) / (pred + target + smooth)))\n",
    "    \n",
    "    print(loss)\n",
    "    \n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1620, 0.3678, 0.3678])\n",
      "bce: tensor(0.7617) , dice: tensor(0.2992)\n"
     ]
    }
   ],
   "source": [
    "pred = torch.tensor([0.33, 0.33, 0.33])\n",
    "target = torch.tensor([1, 0, 0], dtype = torch.float)\n",
    "\n",
    "bce = F.binary_cross_entropy_with_logits(pred, target)\n",
    "\n",
    "pred = F.sigmoid(pred)\n",
    "dice = dice_loss(pred, target)\n",
    "\n",
    "print('bce:', bce, ', dice:', dice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0985, 0.3333, 0.3333])\n",
      "bce: tensor(0.5665) , dice: tensor(0.2550)\n"
     ]
    }
   ],
   "source": [
    "pred = torch.tensor([1.0, 0.0, 0.0])\n",
    "target = torch.tensor([1, 0, 0], dtype = torch.float)\n",
    "\n",
    "bce = F.binary_cross_entropy_with_logits(pred, target)\n",
    "\n",
    "pred = F.sigmoid(pred)\n",
    "dice = dice_loss(pred, target)\n",
    "\n",
    "print('bce:', bce, ', dice:', dice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]'"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "from Unet.loss import dice_loss\n",
    "\n",
    "def calc_loss(pred, target, metrics, bce_weight=0.5):\n",
    "    bce = F.binary_cross_entropy_with_logits(pred, target)\n",
    "\n",
    "    pred = F.sigmoid(pred)\n",
    "#     dice = dice_loss(pred, target)\n",
    "\n",
    "#     loss = bce * bce_weight + dice * (1 - bce_weight)\n",
    "\n",
    "    metrics['bce'] += bce.data.cpu().numpy() * target.size(0)\n",
    "#     metrics['dice'] += dice.data.cpu().numpy() * target.size(0)\n",
    "#     metrics['loss'] += loss.data.cpu().numpy() * target.size(0)\n",
    "\n",
    "#     return loss\n",
    "    return bce\n",
    "\n",
    "\n",
    "\n",
    "def print_metrics(metrics, epoch_samples, phase):\n",
    "    outputs = []\n",
    "    for k in metrics.keys():\n",
    "        outputs.append(\"{}: {:4f}\".format(k, metrics[k] / epoch_samples))\n",
    "\n",
    "    print(\"{}: {}\".format(phase, \", \".join(outputs)))\n",
    "\n",
    "def train_model(model, optimizer, scheduler, num_epochs=25):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 1e10\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        since = time.time()\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    print(\"LR\", param_group['lr'])\n",
    "\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            metrics = defaultdict(float)\n",
    "            epoch_samples = 0\n",
    "\n",
    "            for g in dataloaders[phase]:\n",
    "                \n",
    "                x = g.x\n",
    "                edge_index = g.edge_index\n",
    "                y = g.y.type(torch.float32)\n",
    "\n",
    "                x = x.to(device)\n",
    "                edge_index = edge_index.to(device)\n",
    "                y = y.to(device)                \n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(x, edge_index).squeeze()\n",
    "                    loss = calc_loss(outputs, y, metrics)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                epoch_samples += x.size(0)\n",
    "\n",
    "            print_metrics(metrics, epoch_samples, phase)\n",
    "            epoch_loss = metrics['loss'] / epoch_samples\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                print(\"saving best model\")\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    print('Best val loss: {:4f}'.format(best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Epoch 0/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.568142\n",
      "val: bce: 0.554296\n",
      "saving best model\n",
      "0m 15s\n",
      "Epoch 1/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.540643\n",
      "val: bce: 0.529735\n",
      "0m 15s\n",
      "Epoch 2/59\n",
      "----------\n",
      "LR 0.0001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-202-392352147405>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStepLR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer_ft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-201-f59b050427a8>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mepoch_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch_geometric\\data\\dataloader.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(data_list)\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             collate_fn=lambda data_list: Batch.from_data_list(\n\u001b[1;32m---> 32\u001b[1;33m                 data_list, follow_batch),\n\u001b[0m\u001b[0;32m     33\u001b[0m             **kwargs)\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch_geometric\\data\\batch.py\u001b[0m in \u001b[0;36mfrom_data_list\u001b[1;34m(data_list, follow_batch)\u001b[0m\n\u001b[0;32m     47\u001b[0m                 \u001b[0mitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m                     \u001b[0mitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcumsum\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m                     \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__cat_dim__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import copy\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "num_class = 2\n",
    "\n",
    "# freeze backbone layers\n",
    "#for l in model.base_layers:\n",
    "#    for param in l.parameters():\n",
    "#        param.requires_grad = False\n",
    "\n",
    "optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=30, gamma=0.1)\n",
    "\n",
    "model = train_model(model, optimizer_ft, exp_lr_scheduler, num_epochs=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 1 GPU(s)!\n",
      "loss at iteration  0  is  tensor(0.5062, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  1  is  tensor(0.4973, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print('Let\\'s use', torch.cuda.device_count(), 'GPU(s)!')\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "data_list = [graph_constructors.make_pyg_graph_no_edge_attr(*np.array(synthetic_data.make_a_group())).to(device) for _ in range(1)]\n",
    "loader = DataLoader(data_list, batch_size=1)\n",
    "\n",
    "for j in range(2):\n",
    "    \n",
    "    for i, btch in enumerate(loader):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(btch.x, btch.edge_index)\n",
    "\n",
    "        y = btch.y.to(output.device)\n",
    "        loss = F.nll_loss(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print('loss at iteration ', j ,' is ', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-ce9ac3c425ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mosp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mosp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mosp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'..'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'data'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'MUTAG'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTUDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'MUTAG'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "path = osp.join(osp.dirname(osp.realpath(__file__)), '..', 'data', 'MUTAG')\n",
    "dataset = TUDataset(path, name='MUTAG').shuffle()\n",
    "test_dataset = dataset[:len(dataset) // 10]\n",
    "train_dataset = dataset[len(dataset) // 10:]\n",
    "test_loader = DataLoader(test_dataset, batch_size=128)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data_utils.graph_constructors' from 'C:\\\\Users\\\\andy.knapper\\\\Documents\\\\OW\\\\Categorisation\\\\ML grouping\\\\GNN-for-trans-grouping\\\\data_utils\\\\graph_constructors.py'>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(synthetic_data)\n",
    "importlib.reload(graph_constructors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [graph_constructors.make_pyg_graph_no_edge_attr(*np.array(synthetic_data.make_a_group())).to(device) for _ in range(32)]\n",
    "loader = DataLoader(dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        num_features = 14 #dataset.num_features\n",
    "        dim = 32\n",
    "\n",
    "        nn1 = Sequential(Linear(num_features, dim), ReLU(), Linear(dim, dim))\n",
    "        self.conv1 = GINConv(nn1)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(dim)\n",
    "\n",
    "        nn2 = Sequential(Linear(dim, dim), ReLU(), Linear(dim, dim))\n",
    "        self.conv2 = GINConv(nn2)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(dim)\n",
    "\n",
    "        nn3 = Sequential(Linear(dim, dim), ReLU(), Linear(dim, dim))\n",
    "        self.conv3 = GINConv(nn3)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(dim)\n",
    "\n",
    "        nn4 = Sequential(Linear(dim, dim), ReLU(), Linear(dim, dim))\n",
    "        self.conv4 = GINConv(nn4)\n",
    "        self.bn4 = torch.nn.BatchNorm1d(dim)\n",
    "\n",
    "        nn5 = Sequential(Linear(dim, dim), ReLU(), Linear(dim, dim))\n",
    "        self.conv5 = GINConv(nn5)\n",
    "        self.bn5 = torch.nn.BatchNorm1d(dim)\n",
    "\n",
    "        self.fc1 = Linear(dim, dim)\n",
    "#         self.fc2 = Linear(dim, dataset.num_classes)\n",
    "        self.fc2 = Linear(dim, 2)\n",
    "        \n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(self.conv4(x, edge_index))\n",
    "        x = self.bn4(x)\n",
    "        x = F.relu(self.conv5(x, edge_index))\n",
    "        x = self.bn5(x)\n",
    "        x = global_add_pool(x, batch)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "\n",
    "    if epoch == 51:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = 0.5 * param_group['lr']\n",
    "\n",
    "    loss_all = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.x, data.edge_index, data.batch)\n",
    "        loss = F.nll_loss(output, data.y)\n",
    "        loss.backward()\n",
    "        loss_all += loss.item() * data.num_graphs\n",
    "        optimizer.step()\n",
    "    return loss_all / len(train_dataset)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        output = model(data.x, data.edge_index, data.batch)\n",
    "        pred = output.max(dim=1)[1]\n",
    "        correct += pred.eq(data.y).sum().item()\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, 101):\n",
    "    train_loss = train(epoch)\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    print('Epoch: {:03d}, Train Loss: {:.7f}, '\n",
    "          'Train Acc: {:.7f}, Test Acc: {:.7f}'.format(epoch, train_loss,\n",
    "                                                       train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First construct the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial model structure\n",
    "\n",
    "#1.embedding on the edge_attr to a lower dim space using a MLP\n",
    "#2.edge to node convolution - might need to hand code class\n",
    "#3.node to edge convolution - probably already exists in PyG\n",
    "#4.repeat above (same convolutions or new ones?)\n",
    "#5.MLP on new edge_attrs\n",
    "#6.softmax on MLP output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import ECConv\n",
    "\n",
    "from torch.nn import Sequential as Seq, Linear as Lin, ReLU\n",
    "from torch_scatter import scatter_mean\n",
    "from torch_geometric.nn import MetaLayer\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data_utils.graph_constructors' from 'C:\\\\Users\\\\andy.knapper\\\\Documents\\\\OW\\\\Categorisation\\\\ML grouping\\\\GNN-for-trans-grouping\\\\data_utils\\\\graph_constructors.py'>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(synthetic_data)\n",
    "importlib.reload(graph_constructors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below is model that I want to implement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/rusty1s/pytorch_geometric/issues/535"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things I can vary:\n",
    "\n",
    "1. Graph construction / pruning  (e.g. bi-directional or not)\n",
    "2. Embedding network and dimensions\n",
    "3. convolution direction to start with (node->edge or edge->node)\n",
    "4. node convolution structure (retain initial features in attr tensor)\n",
    "5. edge convolution structure (retain initial features in attr tensor)\n",
    "6. classification network - how to combine the edge attrs if the graph is bidirectional\n",
    "7. loss criteria - unbalanaced classes, should this be weighted for certain types of mis-classification\n",
    "8. training tricks: batch normalisation, dropout, initialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas:\n",
    "\n",
    "* simplify the combination of groups in each example\n",
    "* recode graph generation to only have edges in one direction (make the amount edge property an abs value)\n",
    "* prune the edges from the graphs to make them more sparse\n",
    "* recode the node attr update conv to use only the single directional edge but treat src and dest symmetrically (model code on current edge attr update conv)\n",
    "* make sure the MLP are deep enough and add batch norm and drop out\n",
    "* include multiple iterations of update using differnt convolutions at each stage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "#first create the class to perform the node->edge convolutions\n",
    "#this will be called later in the overall model\n",
    "\n",
    "class MyLayer(torch.nn.Module):\n",
    "    def __init__(self, number_of_node_features, number_of_edge_features):\n",
    "        super(MyLayer, self).__init__()\n",
    "\n",
    "        edge_mlp_channels_in = 2 * number_of_node_features + 10\n",
    "        #only one layer deep at present\n",
    "        self.edge_mlp = Seq(Lin(edge_mlp_channels_in, 10), ReLU())\n",
    "\n",
    "        \n",
    "        def edge_model(src, dest, edge_attr, u, batch):\n",
    "            edge_neighborhoods = torch.cat([src, dest, edge_attr], 1)\n",
    "            return self.edge_mlp(edge_neighborhoods)\n",
    "\n",
    "        self.op = MetaLayer(edge_model)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, u, batch):\n",
    "        return self.op(x, edge_index, edge_attr, u, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, number_of_node_features, number_of_edge_features):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.number_of_node_features = number_of_node_features\n",
    "        self.number_of_edge_features = number_of_edge_features\n",
    "        \n",
    "        ##############################################################################################\n",
    "        #initialise edge embedding MLP\n",
    "        self.edge_embed_lin1 = Lin(self.number_of_edge_features, 20)\n",
    "        self.edge_embed_lin2 = Lin(20, 10)\n",
    "        self.edge_embed_act1 = ReLU()\n",
    "        self.edge_embed_act2 = ReLU()\n",
    "        \n",
    "        self.edge_embed_mlp = Seq(self.edge_embed_lin1, nn.BatchNorm1d(20), self.edge_embed_act1, self.edge_embed_lin2, nn.BatchNorm1d(10), self.edge_embed_act2)\n",
    "        #self.edge_embed_mlp = Seq(self.edge_embed_lin1, self.edge_embed_act1, self.edge_embed_lin2,  self.edge_embed_act2)\n",
    "        \n",
    "        \n",
    "        ##############################################################################################\n",
    "        #initialise edge conditioned convolution to update node attributes by propagating surrounding node attributes via edge attributes\n",
    "        \n",
    "        self.node_update_conv_nn_1 = Seq(Lin(10, 5), nn.BatchNorm1d(5) ,ReLU(), Lin(5, self.number_of_node_features*self.number_of_node_features), nn.BatchNorm1d(self.number_of_node_features*self.number_of_node_features), ReLU())\n",
    "        self.node_update_conv_1 = ECConv(in_channels = self.number_of_node_features,out_channels=self.number_of_node_features, nn = self.node_update_conv_nn_1, aggr='add', root_weight=True, bias=True)\n",
    "        \n",
    "        self.node_update_conv_nn_2 = Seq(Lin(10, 5), nn.BatchNorm1d(5) ,ReLU(), Lin(5, self.number_of_node_features*self.number_of_node_features), nn.BatchNorm1d(self.number_of_node_features*self.number_of_node_features), ReLU())\n",
    "        self.node_update_conv_2 = ECConv(in_channels = self.number_of_node_features,out_channels=self.number_of_node_features, nn = self.node_update_conv_nn_2, aggr='add', root_weight=True, bias=True)\n",
    "        \n",
    "        self.node_update_conv_nn_3 = Seq(Lin(10, 5), nn.BatchNorm1d(5) ,ReLU(), Lin(5, self.number_of_node_features*self.number_of_node_features), nn.BatchNorm1d(self.number_of_node_features*self.number_of_node_features), ReLU())\n",
    "        self.node_update_conv_3 = ECConv(in_channels = self.number_of_node_features,out_channels=self.number_of_node_features, nn = self.node_update_conv_nn_3, aggr='add', root_weight=True, bias=True)\n",
    "        \n",
    "        \n",
    "        #############################################################################################\n",
    "        #initialise the edge_attr updates from the node attrs\n",
    "        \n",
    "        self.edge_update_conv_1 = MyLayer(number_of_node_features, 10)\n",
    "        \n",
    "        self.edge_update_conv_2 = MyLayer(number_of_node_features, 10)\n",
    "        \n",
    "        self.edge_update_conv_3 = MyLayer(number_of_node_features, 10)\n",
    "        \n",
    "        \n",
    "        #############################################################################################\n",
    "        #initialise edge classifier MLP\n",
    "        \n",
    "        self.edge_class_lin1 = Lin(10, 5)\n",
    "        self.edge_class_lin2 = Lin(5, 2)\n",
    "        self.edge_class_act1 = ReLU()\n",
    "        self.edge_class_act2 = ReLU()\n",
    "        \n",
    "        self.edge_class_mlp = Seq(self.edge_class_lin1, nn.Dropout(0.5), self.edge_class_act1, self.edge_class_lin2, nn.Dropout(0.5),  self.edge_class_act2)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr, edge_pairs = data.x, data.edge_index, data.edge_attr, data.edge_pairs\n",
    "\n",
    "        \n",
    "        ########################################################################\n",
    "        #embed the edge attributes in a lower dim space      \n",
    "        edge_attr = self.edge_embed_mlp(edge_attr)\n",
    "\n",
    "        \n",
    "        ########################################################################\n",
    "        #iterate the messages\n",
    "        \n",
    "        #update the node attributes\n",
    "        x = self.node_update_conv_1(x, edge_index, edge_attr)\n",
    "        #update the edges attributes\n",
    "        x, edge_attr, _ = self.edge_update_conv_1.forward(x, edge_index, edge_attr, u=None, batch=data.batch)\n",
    "               \n",
    "        #update the node attributes\n",
    "        x = self.node_update_conv_2(x, edge_index, edge_attr)\n",
    "        #update the edges attributes\n",
    "        x, edge_attr, _ = self.edge_update_conv_2.forward(x, edge_index, edge_attr, u=None, batch=data.batch)\n",
    "        \n",
    "        #update the node attributes\n",
    "        x = self.node_update_conv_3(x, edge_index, edge_attr)\n",
    "        #update the edges attributes\n",
    "        x, edge_attr, _ = self.edge_update_conv_3.forward(x, edge_index, edge_attr, u=None, batch=data.batch)\n",
    "        \n",
    "            \n",
    "        ######################################################################\n",
    "        #pool the attributes over edge pairs\n",
    "        pooled_edge_attr, _ = torch.max(edge_attr[edge_pairs], 1)\n",
    "            \n",
    "        #apply a classifier to the edge attrs\n",
    "        pooled_edge_attr = self.edge_class_mlp(pooled_edge_attr)\n",
    "\n",
    "        return F.log_softmax(pooled_edge_attr, dim=1)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create the dataloader and iterate the data through the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [graph_constructors.make_pyg_graph_no_edge_attr(*np.array(synthetic_data.make_a_group())).to(device) for _ in range(32)]\n",
    "loader = DataLoader(data_list, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Data(edge_index=[2, 6], pos=[3, 2], x=[3, 14], y=[3]),\n",
       " Data(edge_index=[2, 196], pos=[54, 2], x=[54, 14], y=[54]),\n",
       " Data(edge_index=[2, 24], pos=[11, 2], x=[11, 14], y=[11]),\n",
       " Data(edge_index=[2, 10], pos=[5, 2], x=[5, 14], y=[5]),\n",
       " Data(edge_index=[2, 6], pos=[3, 2], x=[3, 14], y=[3]),\n",
       " Data(edge_index=[2, 100], pos=[28, 2], x=[28, 14], y=[28]),\n",
       " Data(edge_index=[2, 140], pos=[38, 2], x=[38, 14], y=[38]),\n",
       " Data(edge_index=[2, 78], pos=[22, 2], x=[22, 14], y=[22]),\n",
       " Data(edge_index=[2, 20], pos=[8, 2], x=[8, 14], y=[8]),\n",
       " Data(edge_index=[2, 104], pos=[28, 2], x=[28, 14], y=[28]),\n",
       " Data(edge_index=[2, 20], pos=[7, 2], x=[7, 14], y=[7]),\n",
       " Data(edge_index=[2, 72], pos=[21, 2], x=[21, 14], y=[21]),\n",
       " Data(edge_index=[2, 88], pos=[26, 2], x=[26, 14], y=[26]),\n",
       " Data(edge_index=[2, 24], pos=[9, 2], x=[9, 14], y=[9]),\n",
       " Data(edge_index=[2, 98], pos=[27, 2], x=[27, 14], y=[27]),\n",
       " Data(edge_index=[2, 86], pos=[23, 2], x=[23, 14], y=[23]),\n",
       " Data(edge_index=[2, 162], pos=[45, 2], x=[45, 14], y=[45]),\n",
       " Data(edge_index=[2, 182], pos=[47, 2], x=[47, 14], y=[47]),\n",
       " Data(edge_index=[2, 78], pos=[23, 2], x=[23, 14], y=[23]),\n",
       " Data(edge_index=[2, 50], pos=[14, 2], x=[14, 14], y=[14]),\n",
       " Data(edge_index=[2, 22], pos=[8, 2], x=[8, 14], y=[8]),\n",
       " Data(edge_index=[2, 60], pos=[16, 2], x=[16, 14], y=[16]),\n",
       " Data(edge_index=[2, 162], pos=[43, 2], x=[43, 14], y=[43]),\n",
       " Data(edge_index=[2, 64], pos=[17, 2], x=[17, 14], y=[17]),\n",
       " Data(edge_index=[2, 98], pos=[27, 2], x=[27, 14], y=[27]),\n",
       " Data(edge_index=[2, 138], pos=[43, 2], x=[43, 14], y=[43]),\n",
       " Data(edge_index=[2, 56], pos=[22, 2], x=[22, 14], y=[22]),\n",
       " Data(edge_index=[2, 54], pos=[15, 2], x=[15, 14], y=[15]),\n",
       " Data(edge_index=[2, 56], pos=[23, 2], x=[23, 14], y=[23]),\n",
       " Data(edge_index=[2, 120], pos=[34, 2], x=[34, 14], y=[34]),\n",
       " Data(edge_index=[2, 146], pos=[38, 2], x=[38, 14], y=[38]),\n",
       " Data(edge_index=[2, 68], pos=[28, 2], x=[28, 14], y=[28])]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in loader:\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features = data_list[0].x.shape[-1]\n",
    "num_edges = data_list[0].edge_attr.shape[0]\n",
    "edge_features = data_list[0].edge_attr.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andy.knapper\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 1 GPU(s)!\n",
      "loss at iteration  0  is  tensor(0.6791, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  1  is  tensor(0.6742, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  2  is  tensor(0.6856, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  3  is  tensor(0.6721, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  4  is  tensor(0.6629, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  5  is  tensor(0.6668, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  6  is  tensor(0.6390, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  7  is  tensor(0.6643, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  8  is  tensor(0.5942, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-9ca12daf0d7f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m#print(j)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mdata_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mgraph_constructors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_pyg_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msynthetic_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_a_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-9ca12daf0d7f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m#print(j)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mdata_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mgraph_constructors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_pyg_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msynthetic_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_a_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\OW\\Categorisation\\ML grouping\\GNN-for-trans-grouping\\data_utils\\graph_constructors.py\u001b[0m in \u001b[0;36mmake_pyg_graph\u001b[1;34m(inp_day_arr, inp_amt_arr, inp_group_arr)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[1;31m#need to reduce y so we have only 1 output per edge pair and the orders are consistent with the edge pairs tensor that will be used in the training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[0my_bi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_edge_labels_lst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m     \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0my_bi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0medge_pair_idxs_ten\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp_day_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minp_amt_arr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
     ]
    }
   ],
   "source": [
    "model = Net(node_features, edge_features)\n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "print('Let\\'s use', torch.cuda.device_count(), 'GPU(s)!')\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for j in range(10):\n",
    "    \n",
    "    #print(j)\n",
    "    \n",
    "    data_list = [graph_constructors.make_pyg_graph(*np.array(synthetic_data.make_a_group())).to(device) for _ in range(1024)]\n",
    "    loader = DataLoader(data_list, batch_size=8)\n",
    "\n",
    "    for i, btch in enumerate(loader):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(btch)\n",
    "\n",
    "        y = btch.y.to(output.device)\n",
    "        loss = F.nll_loss(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print('loss at iteration ', j ,' is ', loss)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andy.knapper\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 1 GPU(s)!\n",
      "loss at iteration  0  is  tensor(0.7274, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  1  is  tensor(0.7289, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  2  is  tensor(0.7785, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  3  is  tensor(0.7137, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  4  is  tensor(0.7287, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  5  is  tensor(0.7167, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  6  is  tensor(0.7264, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  7  is  tensor(0.7069, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  8  is  tensor(0.6986, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  9  is  tensor(0.7121, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  10  is  tensor(0.6858, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  11  is  tensor(0.6861, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  12  is  tensor(0.7006, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  13  is  tensor(0.7174, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  14  is  tensor(0.6961, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  15  is  tensor(0.7133, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  16  is  tensor(0.6890, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  17  is  tensor(0.7102, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  18  is  tensor(0.6912, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  19  is  tensor(0.7124, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  20  is  tensor(0.7081, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  21  is  tensor(0.6923, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  22  is  tensor(0.7020, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  23  is  tensor(0.7053, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  24  is  tensor(0.6968, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  25  is  tensor(0.7278, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  26  is  tensor(0.6977, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  27  is  tensor(0.7086, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  28  is  tensor(0.6923, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  29  is  tensor(0.6992, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  30  is  tensor(0.6935, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  31  is  tensor(0.6935, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  32  is  tensor(0.6958, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  33  is  tensor(0.6901, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  34  is  tensor(0.6965, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  35  is  tensor(0.6888, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  36  is  tensor(0.6792, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  37  is  tensor(0.6921, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  38  is  tensor(0.6884, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  39  is  tensor(0.6922, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  40  is  tensor(0.6947, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  41  is  tensor(0.6882, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  42  is  tensor(0.6945, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  43  is  tensor(0.6988, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  44  is  tensor(0.6879, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  45  is  tensor(0.6886, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  46  is  tensor(0.6823, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  47  is  tensor(0.7021, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  48  is  tensor(0.6947, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  49  is  tensor(0.7002, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  50  is  tensor(0.6776, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  51  is  tensor(0.6938, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  52  is  tensor(0.6852, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  53  is  tensor(0.6834, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  54  is  tensor(0.6774, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  55  is  tensor(0.6926, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  56  is  tensor(0.6810, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  57  is  tensor(0.6842, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  58  is  tensor(0.6965, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  59  is  tensor(0.6847, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  60  is  tensor(0.6987, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  61  is  tensor(0.7106, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  62  is  tensor(0.7031, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  63  is  tensor(0.6852, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  64  is  tensor(0.7097, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  65  is  tensor(0.6914, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  66  is  tensor(0.6794, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  67  is  tensor(0.6936, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  68  is  tensor(0.6884, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  69  is  tensor(0.6927, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  70  is  tensor(0.6911, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  71  is  tensor(0.6786, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  72  is  tensor(0.6800, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  73  is  tensor(0.6709, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  74  is  tensor(0.6856, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  75  is  tensor(0.6961, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  76  is  tensor(0.6863, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  77  is  tensor(0.6834, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  78  is  tensor(0.6870, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  79  is  tensor(0.6753, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  80  is  tensor(0.6842, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  81  is  tensor(0.7013, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  82  is  tensor(0.6740, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  83  is  tensor(0.6902, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  84  is  tensor(0.6805, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  85  is  tensor(0.6777, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  86  is  tensor(0.6686, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  87  is  tensor(0.6810, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  88  is  tensor(0.6829, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  89  is  tensor(0.6758, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  90  is  tensor(0.6835, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  91  is  tensor(0.6774, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  92  is  tensor(0.6812, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  93  is  tensor(0.6986, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  94  is  tensor(0.6802, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  95  is  tensor(0.6772, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  96  is  tensor(0.6818, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  97  is  tensor(0.6841, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  98  is  tensor(0.6754, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  99  is  tensor(0.6915, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  100  is  tensor(0.6837, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  101  is  tensor(0.6800, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  102  is  tensor(0.6671, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  103  is  tensor(0.6834, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  104  is  tensor(0.6579, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  105  is  tensor(0.6806, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  106  is  tensor(0.6861, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  107  is  tensor(0.6884, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  108  is  tensor(0.6837, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  109  is  tensor(0.6712, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  110  is  tensor(0.6716, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  111  is  tensor(0.6709, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  112  is  tensor(0.6747, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  113  is  tensor(0.6700, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  114  is  tensor(0.6903, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  115  is  tensor(0.6796, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  116  is  tensor(0.6696, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  117  is  tensor(0.6792, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  118  is  tensor(0.6866, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  119  is  tensor(0.6777, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  120  is  tensor(0.6828, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  121  is  tensor(0.6854, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  122  is  tensor(0.6716, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  123  is  tensor(0.6688, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  124  is  tensor(0.6919, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  125  is  tensor(0.6707, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  126  is  tensor(0.6857, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  127  is  tensor(0.6784, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  128  is  tensor(0.6783, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  129  is  tensor(0.6721, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  130  is  tensor(0.6894, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  131  is  tensor(0.6849, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  132  is  tensor(0.6729, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  133  is  tensor(0.6722, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  134  is  tensor(0.6808, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  135  is  tensor(0.6625, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  136  is  tensor(0.6827, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  137  is  tensor(0.6783, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  138  is  tensor(0.6780, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  139  is  tensor(0.6754, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  140  is  tensor(0.6746, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  141  is  tensor(0.6837, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  142  is  tensor(0.6577, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  143  is  tensor(0.6800, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  144  is  tensor(0.6755, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  145  is  tensor(0.6989, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  146  is  tensor(0.6723, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  147  is  tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  148  is  tensor(0.6910, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  149  is  tensor(0.6793, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  150  is  tensor(0.6809, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  151  is  tensor(0.6720, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  152  is  tensor(0.6762, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  153  is  tensor(0.6889, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  154  is  tensor(0.6639, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  155  is  tensor(0.6818, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  156  is  tensor(0.6766, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  157  is  tensor(0.6698, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  158  is  tensor(0.6840, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  159  is  tensor(0.6694, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  160  is  tensor(0.6775, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  161  is  tensor(0.6815, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  162  is  tensor(0.6757, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  163  is  tensor(0.6679, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  164  is  tensor(0.6565, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  165  is  tensor(0.6896, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  166  is  tensor(0.6696, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  167  is  tensor(0.6687, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  168  is  tensor(0.6653, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  169  is  tensor(0.6763, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  170  is  tensor(0.6645, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  171  is  tensor(0.6833, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  172  is  tensor(0.6702, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  173  is  tensor(0.6845, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  174  is  tensor(0.6697, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  175  is  tensor(0.6712, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  176  is  tensor(0.6836, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  177  is  tensor(0.6686, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  178  is  tensor(0.6854, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  179  is  tensor(0.6631, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  180  is  tensor(0.6706, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  181  is  tensor(0.6907, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  182  is  tensor(0.6524, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  183  is  tensor(0.6828, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  184  is  tensor(0.6671, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  185  is  tensor(0.6715, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  186  is  tensor(0.6724, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  187  is  tensor(0.6707, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  188  is  tensor(0.6598, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at iteration  189  is  tensor(0.6828, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  190  is  tensor(0.6715, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  191  is  tensor(0.6632, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  192  is  tensor(0.6797, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  193  is  tensor(0.6835, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  194  is  tensor(0.6806, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  195  is  tensor(0.6848, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  196  is  tensor(0.6587, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  197  is  tensor(0.6707, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  198  is  tensor(0.6907, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  199  is  tensor(0.6636, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  200  is  tensor(0.6762, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  201  is  tensor(0.6891, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  202  is  tensor(0.6759, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  203  is  tensor(0.6653, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  204  is  tensor(0.6730, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  205  is  tensor(0.6570, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  206  is  tensor(0.6823, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  207  is  tensor(0.6724, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  208  is  tensor(0.6915, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  209  is  tensor(0.6873, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  210  is  tensor(0.6974, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  211  is  tensor(0.6573, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  212  is  tensor(0.6870, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  213  is  tensor(0.6759, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  214  is  tensor(0.6743, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  215  is  tensor(0.6806, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  216  is  tensor(0.6582, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  217  is  tensor(0.6787, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  218  is  tensor(0.6677, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  219  is  tensor(0.6787, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  220  is  tensor(0.6720, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  221  is  tensor(0.6633, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  222  is  tensor(0.6682, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  223  is  tensor(0.6710, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  224  is  tensor(0.6756, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  225  is  tensor(0.6791, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  226  is  tensor(0.6786, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  227  is  tensor(0.6488, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  228  is  tensor(0.6803, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  229  is  tensor(0.6705, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  230  is  tensor(0.6752, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  231  is  tensor(0.6732, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  232  is  tensor(0.6599, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  233  is  tensor(0.6714, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  234  is  tensor(0.6775, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  235  is  tensor(0.6801, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  236  is  tensor(0.6704, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  237  is  tensor(0.6617, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  238  is  tensor(0.6518, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  239  is  tensor(0.6852, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  240  is  tensor(0.6802, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  241  is  tensor(0.6842, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  242  is  tensor(0.6588, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  243  is  tensor(0.6804, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  244  is  tensor(0.6770, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  245  is  tensor(0.6753, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  246  is  tensor(0.6891, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  247  is  tensor(0.6770, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  248  is  tensor(0.6757, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  249  is  tensor(0.6714, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  250  is  tensor(0.6560, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  251  is  tensor(0.6485, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  252  is  tensor(0.6797, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  253  is  tensor(0.6601, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  254  is  tensor(0.6807, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  255  is  tensor(0.6627, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  256  is  tensor(0.6837, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  257  is  tensor(0.6732, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  258  is  tensor(0.6705, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  259  is  tensor(0.6732, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  260  is  tensor(0.6548, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  261  is  tensor(0.6834, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  262  is  tensor(0.6836, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  263  is  tensor(0.6732, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  264  is  tensor(0.6719, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  265  is  tensor(0.6708, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  266  is  tensor(0.6734, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  267  is  tensor(0.6720, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  268  is  tensor(0.6755, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  269  is  tensor(0.6633, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  270  is  tensor(0.6641, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  271  is  tensor(0.6750, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  272  is  tensor(0.6609, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  273  is  tensor(0.6696, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  274  is  tensor(0.6689, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  275  is  tensor(0.6660, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  276  is  tensor(0.6717, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  277  is  tensor(0.6768, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  278  is  tensor(0.6692, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  279  is  tensor(0.6657, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  280  is  tensor(0.6636, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  281  is  tensor(0.6685, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  282  is  tensor(0.6789, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  283  is  tensor(0.6812, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  284  is  tensor(0.6667, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  285  is  tensor(0.6702, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  286  is  tensor(0.6614, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  287  is  tensor(0.6604, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  288  is  tensor(0.6666, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  289  is  tensor(0.6792, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  290  is  tensor(0.6660, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  291  is  tensor(0.6782, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  292  is  tensor(0.6676, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  293  is  tensor(0.6751, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  294  is  tensor(0.6717, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  295  is  tensor(0.6673, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  296  is  tensor(0.6665, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  297  is  tensor(0.6538, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  298  is  tensor(0.6538, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  299  is  tensor(0.6740, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  300  is  tensor(0.6887, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  301  is  tensor(0.6511, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  302  is  tensor(0.6481, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  303  is  tensor(0.6660, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  304  is  tensor(0.6551, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  305  is  tensor(0.6580, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  306  is  tensor(0.6687, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  307  is  tensor(0.6695, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  308  is  tensor(0.6596, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  309  is  tensor(0.6637, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  310  is  tensor(0.6648, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  311  is  tensor(0.6463, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  312  is  tensor(0.6519, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  313  is  tensor(0.6683, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  314  is  tensor(0.6742, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  315  is  tensor(0.6708, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  316  is  tensor(0.6642, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  317  is  tensor(0.6731, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  318  is  tensor(0.6652, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  319  is  tensor(0.6670, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  320  is  tensor(0.6553, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  321  is  tensor(0.6635, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  322  is  tensor(0.6730, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  323  is  tensor(0.6644, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  324  is  tensor(0.6649, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  325  is  tensor(0.6698, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  326  is  tensor(0.6742, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  327  is  tensor(0.6669, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  328  is  tensor(0.6419, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  329  is  tensor(0.6431, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  330  is  tensor(0.6679, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  331  is  tensor(0.6617, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  332  is  tensor(0.6727, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  333  is  tensor(0.6619, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  334  is  tensor(0.6789, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  335  is  tensor(0.6673, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  336  is  tensor(0.6632, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  337  is  tensor(0.6526, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  338  is  tensor(0.6507, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  339  is  tensor(0.6474, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  340  is  tensor(0.6591, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  341  is  tensor(0.6545, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  342  is  tensor(0.6532, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  343  is  tensor(0.6305, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  344  is  tensor(0.6761, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  345  is  tensor(0.6640, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  346  is  tensor(0.6711, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  347  is  tensor(0.6564, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  348  is  tensor(0.6556, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  349  is  tensor(0.6765, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  350  is  tensor(0.6590, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  351  is  tensor(0.6518, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  352  is  tensor(0.6655, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  353  is  tensor(0.6628, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  354  is  tensor(0.6750, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  355  is  tensor(0.6650, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  356  is  tensor(0.6699, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  357  is  tensor(0.6404, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  358  is  tensor(0.6704, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  359  is  tensor(0.6650, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  360  is  tensor(0.6692, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  361  is  tensor(0.6508, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  362  is  tensor(0.6638, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  363  is  tensor(0.6641, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  364  is  tensor(0.6846, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  365  is  tensor(0.6690, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  366  is  tensor(0.6585, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  367  is  tensor(0.6596, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  368  is  tensor(0.6757, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  369  is  tensor(0.6484, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  370  is  tensor(0.6640, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  371  is  tensor(0.6400, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  372  is  tensor(0.6789, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  373  is  tensor(0.6667, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  374  is  tensor(0.6782, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  375  is  tensor(0.6611, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  376  is  tensor(0.6280, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at iteration  377  is  tensor(0.6355, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  378  is  tensor(0.6563, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  379  is  tensor(0.6702, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  380  is  tensor(0.6767, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  381  is  tensor(0.6607, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  382  is  tensor(0.6751, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  383  is  tensor(0.6301, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  384  is  tensor(0.6439, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  385  is  tensor(0.6479, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  386  is  tensor(0.6452, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  387  is  tensor(0.6351, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  388  is  tensor(0.6578, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  389  is  tensor(0.6381, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  390  is  tensor(0.6338, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  391  is  tensor(0.6605, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  392  is  tensor(0.6443, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  393  is  tensor(0.6339, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  394  is  tensor(0.6283, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  395  is  tensor(0.6448, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  396  is  tensor(0.6347, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  397  is  tensor(0.6365, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  398  is  tensor(0.6165, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  399  is  tensor(0.6306, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  400  is  tensor(0.6350, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  401  is  tensor(0.6488, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  402  is  tensor(0.6616, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  403  is  tensor(0.6458, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  404  is  tensor(0.6296, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  405  is  tensor(0.6405, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  406  is  tensor(0.6196, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  407  is  tensor(0.6499, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  408  is  tensor(0.6359, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  409  is  tensor(0.6166, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  410  is  tensor(0.6389, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  411  is  tensor(0.6419, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  412  is  tensor(0.6251, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  413  is  tensor(0.6281, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  414  is  tensor(0.6451, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  415  is  tensor(0.6330, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  416  is  tensor(0.6507, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  417  is  tensor(0.6367, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  418  is  tensor(0.6504, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  419  is  tensor(0.6372, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  420  is  tensor(0.6343, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  421  is  tensor(0.6378, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  422  is  tensor(0.6504, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  423  is  tensor(0.6343, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  424  is  tensor(0.6264, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  425  is  tensor(0.6507, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  426  is  tensor(0.6369, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  427  is  tensor(0.6399, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  428  is  tensor(0.6311, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  429  is  tensor(0.6299, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  430  is  tensor(0.6193, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-6cdf2af585f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'loss at iteration '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;34m' is '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    101\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m                     \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Net(node_features, edge_features)\n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "print('Let\\'s use', torch.cuda.device_count(), 'GPU(s)!')\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "data_list = [graph_constructors.make_pyg_graph(*np.array(synthetic_data.make_a_group())).to(device) for _ in range(1)]\n",
    "loader = DataLoader(data_list, batch_size=1)\n",
    "\n",
    "for j in range(1000):\n",
    "    \n",
    "    for i, btch in enumerate(loader):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(btch)\n",
    "\n",
    "        y = btch.y.to(output.device)\n",
    "        loss = F.nll_loss(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print('loss at iteration ', j ,' is ', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build up the model to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data_utils.graph_constructors' from 'C:\\\\Users\\\\andy.knapper\\\\Documents\\\\OW\\\\Categorisation\\\\ML grouping\\\\GNN-for-trans-grouping\\\\data_utils\\\\graph_constructors.py'>"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(synthetic_data)\n",
    "importlib.reload(graph_constructors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://discuss.pytorch.org/t/check-gradient-flow-in-network/15063/8\n",
    "\n",
    "def plot_grad_flow(named_parameters):\n",
    "    '''Plots the gradients flowing through different layers in the net during training.\n",
    "    Can be used for checking for possible gradient vanishing / exploding problems.\n",
    "    \n",
    "    Usage: Plug this function in Trainer class after loss.backwards() as \n",
    "    \"plot_grad_flow(self.model.named_parameters())\" to visualize the gradient flow'''\n",
    "    ave_grads = []\n",
    "    max_grads= []\n",
    "    layers = []\n",
    "    for n, p in named_parameters:\n",
    "        if(p.requires_grad) and (\"bias\" not in n):\n",
    "            layers.append(n)\n",
    "            ave_grads.append(p.grad.abs().mean())\n",
    "            max_grads.append(p.grad.abs().max())\n",
    "    plt.bar(np.arange(len(max_grads)), max_grads, alpha=0.1, lw=1, color=\"c\")\n",
    "    plt.bar(np.arange(len(max_grads)), ave_grads, alpha=0.1, lw=1, color=\"b\")\n",
    "    plt.hlines(0, 0, len(ave_grads)+1, lw=2, color=\"k\" )\n",
    "    plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n",
    "    plt.xlim(left=0, right=len(ave_grads))\n",
    "    plt.ylim(bottom = -0.001, top=0.02) # zoom in on the lower gradient regions\n",
    "    plt.xlabel(\"Layers\")\n",
    "    plt.ylabel(\"average gradient\")\n",
    "    plt.title(\"Gradient flow\")\n",
    "    plt.grid(True)\n",
    "    plt.legend([matplotlib.lines.Line2D([0], [0], color=\"c\", lw=4),\n",
    "                matplotlib.lines.Line2D([0], [0], color=\"b\", lw=4),\n",
    "                matplotlib.lines.Line2D([0], [0], color=\"k\", lw=4)], ['max-gradient', 'mean-gradient', 'zero-gradient'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, number_of_node_features, number_of_edge_features):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.number_of_node_features = number_of_node_features\n",
    "        self.number_of_edge_features = number_of_edge_features\n",
    "        \n",
    "        ##############################################################################################\n",
    "        #initialise edge embedding MLP\n",
    "        self.edge_embed_lin1 = Lin(self.number_of_edge_features, 10)\n",
    "#         self.edge_embed_lin2 = Lin(20, 10)\n",
    "        self.edge_embed_act1 = ReLU()\n",
    "#         self.edge_embed_act2 = ReLU()\n",
    "        \n",
    "        self.edge_embed_mlp = Seq(self.edge_embed_lin1, self.edge_embed_act1)    \n",
    "#         self.edge_embed_mlp = Seq(self.edge_embed_lin1, nn.BatchNorm1d(20), self.edge_embed_act1, self.edge_embed_lin2, nn.BatchNorm1d(10), self.edge_embed_act2)\n",
    "#         self.edge_embed_mlp = Seq(self.edge_embed_lin1, self.edge_embed_act1, self.edge_embed_lin2,  self.edge_embed_act2)\n",
    "        \n",
    "        \n",
    "#         ##############################################################################################\n",
    "#         #initialise edge conditioned convolution to update node attributes by propagating surrounding node attributes via edge attributes\n",
    "        \n",
    "        self.node_update_conv_nn_1 = Seq(Lin(10, self.number_of_node_features*self.number_of_node_features), nn.BatchNorm1d(self.number_of_node_features*self.number_of_node_features), ReLU())\n",
    "        self.node_update_conv_1 = ECConv(in_channels = self.number_of_node_features,out_channels=self.number_of_node_features, nn = self.node_update_conv_nn_1, aggr='add', root_weight=True, bias=True)\n",
    "         \n",
    "#         self.node_update_conv_nn_2 = Seq(Lin(10, self.number_of_node_features*self.number_of_node_features), nn.BatchNorm1d(self.number_of_node_features*self.number_of_node_features), ReLU())\n",
    "#         self.node_update_conv_2 = ECConv(in_channels = self.number_of_node_features,out_channels=self.number_of_node_features, nn = self.node_update_conv_nn_2, aggr='add', root_weight=True, bias=True)\n",
    "         \n",
    "#         self.node_update_conv_nn_3 = Seq(Lin(10, self.number_of_node_features*self.number_of_node_features), nn.BatchNorm1d(self.number_of_node_features*self.number_of_node_features), ReLU())\n",
    "#         self.node_update_conv_3 = ECConv(in_channels = self.number_of_node_features,out_channels=self.number_of_node_features, nn = self.node_update_conv_nn_3, aggr='add', root_weight=True, bias=True)\n",
    "         \n",
    "            \n",
    "#         self.node_update_conv_nn_1 = Seq(Lin(10, 5), nn.BatchNorm1d(5) ,ReLU(), Lin(5, self.number_of_node_features*self.number_of_node_features), nn.BatchNorm1d(self.number_of_node_features*self.number_of_node_features), ReLU())\n",
    "#         self.node_update_conv_1 = ECConv(in_channels = self.number_of_node_features,out_channels=self.number_of_node_features, nn = self.node_update_conv_nn_1, aggr='add', root_weight=True, bias=True)\n",
    "        \n",
    "#         self.node_update_conv_nn_2 = Seq(Lin(10, 5), nn.BatchNorm1d(5) ,ReLU(), Lin(5, self.number_of_node_features*self.number_of_node_features), nn.BatchNorm1d(self.number_of_node_features*self.number_of_node_features), ReLU())\n",
    "#         self.node_update_conv_2 = ECConv(in_channels = self.number_of_node_features,out_channels=self.number_of_node_features, nn = self.node_update_conv_nn_2, aggr='add', root_weight=True, bias=True)\n",
    "        \n",
    "#         self.node_update_conv_nn_3 = Seq(Lin(10, 5), nn.BatchNorm1d(5) ,ReLU(), Lin(5, self.number_of_node_features*self.number_of_node_features), nn.BatchNorm1d(self.number_of_node_features*self.number_of_node_features), ReLU())\n",
    "#         self.node_update_conv_3 = ECConv(in_channels = self.number_of_node_features,out_channels=self.number_of_node_features, nn = self.node_update_conv_nn_3, aggr='add', root_weight=True, bias=True)\n",
    "        \n",
    "        \n",
    "#         #############################################################################################\n",
    "#         #initialise the edge_attr updates from the node attrs\n",
    "        \n",
    "        self.edge_update_conv_1 = MyLayer(number_of_node_features, 10)\n",
    "        \n",
    "#         self.edge_update_conv_2 = MyLayer(number_of_node_features, 10)\n",
    "        \n",
    "#         self.edge_update_conv_3 = MyLayer(number_of_node_features, 10)\n",
    "        \n",
    "        \n",
    "        #############################################################################################\n",
    "        #initialise edge classifier MLP\n",
    "        \n",
    "#         self.edge_class_lin1 = Lin(10, 5)\n",
    "        self.edge_class_lin1 = Lin(10, 2)\n",
    "#         self.edge_class_lin2 = Lin(5, 2)\n",
    "        self.edge_class_act1 = ReLU()\n",
    "#         self.edge_class_act2 = ReLU()\n",
    "        \n",
    "#         self.edge_class_mlp = Seq(self.edge_class_lin1, nn.Dropout(0.5), self.edge_class_act1, self.edge_class_lin2, nn.Dropout(0.5),  self.edge_class_act2)\n",
    "        self.edge_class_mlp = Seq(self.edge_class_lin1, self.edge_class_act1)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr, edge_pairs = data.x, data.edge_index, data.edge_attr, data.edge_pairs\n",
    "\n",
    "        \n",
    "        ########################################################################\n",
    "        #embed the edge attributes in a lower dim space      \n",
    "        edge_attr = self.edge_embed_mlp(edge_attr)\n",
    "\n",
    "        \n",
    "        ########################################################################\n",
    "        #iterate the messages\n",
    "        \n",
    "        for _ in range(10):\n",
    "    #         #update the node attributes\n",
    "            x = self.node_update_conv_1(x, edge_index, edge_attr)\n",
    "            #update the edges attributes\n",
    "            x, edge_attr, _ = self.edge_update_conv_1.forward(x, edge_index, edge_attr, u=None, batch=data.batch)\n",
    "               \n",
    "#         #update the node attributes\n",
    "#         x = self.node_update_conv_1(x, edge_index, edge_attr)\n",
    "#         #update the edges attributes\n",
    "#         x, edge_attr, _ = self.edge_update_conv_1.forward(x, edge_index, edge_attr, u=None, batch=data.batch)\n",
    "            \n",
    "#         #update the node attributes\n",
    "#         x = self.node_update_conv_1(x, edge_index, edge_attr)\n",
    "#         #update the edges attributes\n",
    "#         x, edge_attr, _ = self.edge_update_conv_1.forward(x, edge_index, edge_attr, u=None, batch=data.batch)\n",
    "            \n",
    "#         #update the node attributes\n",
    "#         x = self.node_update_conv_2(x, edge_index, edge_attr)\n",
    "#         #update the edges attributes\n",
    "#         x, edge_attr, _ = self.edge_update_conv_2.forward(x, edge_index, edge_attr, u=None, batch=data.batch)\n",
    "        \n",
    "#         #update the node attributes\n",
    "#         x = self.node_update_conv_3(x, edge_index, edge_attr)\n",
    "#         #update the edges attributes\n",
    "#         x, edge_attr, _ = self.edge_update_conv_3.forward(x, edge_index, edge_attr, u=None, batch=data.batch)\n",
    "        \n",
    "            \n",
    "        ######################################################################\n",
    "        #pool the attributes over edge pairs\n",
    "        pooled_edge_attr, _ = torch.max(edge_attr[edge_pairs], 1)\n",
    "            \n",
    "        #apply a classifier to the edge attrs\n",
    "        pooled_edge_attr = self.edge_class_mlp(pooled_edge_attr)\n",
    "#         edge_attr = self.edge_class_mlp(edge_attr)\n",
    "#         print('edge_attr', edge_attr)\n",
    "#         print('F.log_softmax(edge_attr, dim=1)', F.log_softmax(edge_attr, dim=1))\n",
    "\n",
    "#         return F.log_softmax(edge_attr, dim=1)\n",
    "        return F.log_softmax(pooled_edge_attr, dim=1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_embed_lin1.weight Parameter containing:\n",
      "tensor([[ 0.0509,  0.0645,  0.0999, -0.0659, -0.0738,  0.0904, -0.0889, -0.0239,\n",
      "         -0.0107,  0.0481,  0.0866, -0.0480,  0.0323, -0.0583,  0.0865,  0.0793,\n",
      "         -0.0656,  0.0524,  0.0773, -0.0981, -0.0036, -0.0825, -0.0257,  0.0081,\n",
      "          0.0529,  0.0825, -0.0206,  0.0031,  0.0718,  0.0257,  0.0163,  0.0511,\n",
      "          0.0977,  0.0623, -0.0355,  0.0954,  0.0647,  0.0112,  0.0941,  0.0261,\n",
      "         -0.0295, -0.0957,  0.0294, -0.0186,  0.0450, -0.0507, -0.0791, -0.0511,\n",
      "          0.0659,  0.0796,  0.0190,  0.0287, -0.0827, -0.0563,  0.0934,  0.0647,\n",
      "         -0.0248,  0.0444, -0.0841, -0.0845,  0.0751,  0.0979, -0.0136, -0.0183,\n",
      "         -0.0040, -0.0254, -0.0497, -0.0352,  0.0632, -0.0959, -0.0721,  0.0060,\n",
      "          0.0879, -0.0172,  0.0638, -0.0969, -0.0044,  0.0585, -0.0198, -0.0005,\n",
      "          0.0286,  0.0480, -0.1016,  0.0893, -0.0624, -0.0920,  0.0100, -0.0501,\n",
      "          0.0623,  0.0746,  0.0789, -0.0498, -0.0113],\n",
      "        [ 0.0071, -0.0209,  0.0914,  0.0194, -0.0493, -0.0382,  0.0540,  0.0497,\n",
      "          0.0987,  0.0372, -0.0188, -0.0522,  0.0631,  0.0257, -0.0577,  0.0483,\n",
      "          0.0491, -0.0022,  0.1012, -0.0149,  0.0260, -0.0568, -0.0654,  0.0277,\n",
      "          0.0349,  0.0496,  0.0236, -0.0413,  0.0646, -0.0306,  0.0411, -0.0647,\n",
      "         -0.0013, -0.0766, -0.0875, -0.0499,  0.0415,  0.0140, -0.0602,  0.0084,\n",
      "          0.0072, -0.0107, -0.0606,  0.0143,  0.0219, -0.1018,  0.0374, -0.0864,\n",
      "         -0.0737,  0.0510,  0.0409,  0.0028,  0.0066, -0.0351,  0.0824,  0.0699,\n",
      "         -0.0077,  0.0868,  0.0877, -0.0108,  0.0847,  0.0157,  0.0420,  0.1026,\n",
      "         -0.0447, -0.0220, -0.0478, -0.0701,  0.0085, -0.0807, -0.0952,  0.0189,\n",
      "          0.0255,  0.0335, -0.0493,  0.0271, -0.0222, -0.0221, -0.0525, -0.0765,\n",
      "          0.0521, -0.0537,  0.0209,  0.0968, -0.0590,  0.0381,  0.0190, -0.0148,\n",
      "         -0.0098,  0.0714, -0.0170,  0.0881,  0.0726],\n",
      "        [ 0.0324,  0.0890, -0.0796, -0.0719, -0.0979, -0.0882, -0.0155,  0.0279,\n",
      "          0.0489, -0.0272, -0.0463,  0.0476,  0.0067,  0.0138, -0.0897, -0.0188,\n",
      "         -0.0622, -0.0390,  0.0070,  0.0034, -0.0179, -0.0375,  0.0903, -0.0880,\n",
      "          0.0859,  0.0826, -0.0183,  0.0234, -0.0226,  0.0627,  0.1022,  0.0966,\n",
      "          0.0768,  0.0044,  0.0709,  0.0551,  0.0741, -0.0699, -0.0602, -0.0128,\n",
      "         -0.0492, -0.0092, -0.0417, -0.0766,  0.0667,  0.0757,  0.0570,  0.0765,\n",
      "          0.0532, -0.0757, -0.0021, -0.0188,  0.0591,  0.0332,  0.0211, -0.0697,\n",
      "          0.0654,  0.0183,  0.0323,  0.0980, -0.0481,  0.0257,  0.0170,  0.0794,\n",
      "          0.0475, -0.0217, -0.0425,  0.1022, -0.0789,  0.0935, -0.0867,  0.0862,\n",
      "          0.0998,  0.0890,  0.0622, -0.0273, -0.0843, -0.0211, -0.0777, -0.0072,\n",
      "         -0.0518,  0.0992,  0.0663,  0.0431, -0.0859, -0.0213,  0.0044,  0.0934,\n",
      "          0.0488,  0.0497, -0.0620, -0.0520,  0.0355],\n",
      "        [ 0.0907,  0.0585,  0.0727,  0.0917,  0.0129,  0.0658,  0.0627,  0.0827,\n",
      "         -0.0852,  0.0754,  0.0022,  0.0390,  0.0099,  0.0656,  0.0643,  0.0199,\n",
      "         -0.0735,  0.0821, -0.0654,  0.0786, -0.0697,  0.0432,  0.0501, -0.0563,\n",
      "         -0.0124, -0.0476, -0.0389,  0.0970, -0.0668, -0.0217, -0.0558,  0.0543,\n",
      "          0.0651, -0.0881,  0.0882, -0.0653, -0.0506, -0.0291, -0.0743,  0.0032,\n",
      "          0.0805,  0.0674,  0.0874, -0.0262,  0.0649, -0.0333, -0.0496,  0.0141,\n",
      "          0.1008,  0.0684, -0.0898,  0.0358,  0.0041, -0.0385, -0.0600,  0.0297,\n",
      "         -0.0523,  0.0123,  0.0419, -0.0311,  0.0563, -0.0629, -0.0053,  0.0866,\n",
      "         -0.1018,  0.0142, -0.0445, -0.0601,  0.0681, -0.0910, -0.0789, -0.0370,\n",
      "          0.0889,  0.0467, -0.0793,  0.0910,  0.1014, -0.0565, -0.0115, -0.0159,\n",
      "         -0.0105,  0.0162,  0.0768,  0.0229,  0.0923, -0.0576,  0.0577,  0.0648,\n",
      "         -0.0500,  0.0118, -0.0558, -0.0339, -0.0218],\n",
      "        [-0.0961, -0.0412,  0.0883,  0.0923,  0.0755,  0.0540, -0.0242,  0.0439,\n",
      "         -0.0174, -0.0499,  0.0585, -0.0204, -0.0987,  0.0743,  0.0296,  0.0197,\n",
      "          0.0080, -0.0986,  0.0377,  0.0914,  0.0795,  0.0456, -0.0973,  0.0769,\n",
      "         -0.0084,  0.0249, -0.0897,  0.0697,  0.0716,  0.0665, -0.0936, -0.0657,\n",
      "          0.0237,  0.0791,  0.0872, -0.0357, -0.0493,  0.0995,  0.0724,  0.0950,\n",
      "         -0.0692,  0.0134, -0.0810,  0.0911,  0.0873, -0.0180, -0.0628,  0.0730,\n",
      "         -0.0639, -0.0028, -0.0048,  0.0143,  0.0293, -0.0734,  0.1025,  0.0177,\n",
      "          0.0630, -0.0856, -0.0180, -0.0299, -0.0793, -0.0525,  0.0203,  0.0534,\n",
      "          0.0586,  0.0092, -0.0558, -0.0136,  0.0854, -0.0970,  0.0993, -0.0589,\n",
      "         -0.0588, -0.0230,  0.0278, -0.1010,  0.0994, -0.0642, -0.0582,  0.0680,\n",
      "          0.0396, -0.0979,  0.0886, -0.0021, -0.1024,  0.0815,  0.0013,  0.0935,\n",
      "         -0.0537, -0.0923, -0.1022, -0.1019,  0.0158],\n",
      "        [ 0.0013, -0.0036, -0.0573, -0.0223, -0.0235,  0.0129,  0.0339,  0.0892,\n",
      "          0.0969, -0.0337,  0.0923,  0.0057,  0.0612, -0.0520, -0.0764, -0.0664,\n",
      "         -0.0782,  0.0086,  0.0285,  0.0903, -0.0562, -0.0155,  0.0361,  0.0597,\n",
      "         -0.0010, -0.0133, -0.0279,  0.0291,  0.0974,  0.0212,  0.0428,  0.0819,\n",
      "          0.0843,  0.0145, -0.0394, -0.0858,  0.0987, -0.0212, -0.0268, -0.0390,\n",
      "         -0.1023, -0.0957, -0.0277, -0.0668,  0.0003, -0.0176,  0.0969, -0.0685,\n",
      "          0.0414,  0.0193, -0.0284,  0.0333,  0.0397,  0.0299, -0.0900, -0.0311,\n",
      "         -0.0343,  0.0644,  0.0388, -0.0560, -0.0607,  0.0313, -0.0204, -0.0231,\n",
      "          0.0257,  0.0269,  0.0331,  0.0952,  0.0756,  0.0665,  0.0529, -0.0216,\n",
      "          0.0622,  0.0625,  0.0447, -0.0238, -0.0413,  0.0933,  0.0283,  0.0390,\n",
      "         -0.0691, -0.0598, -0.0419, -0.0953,  0.0848,  0.0207, -0.0425,  0.0957,\n",
      "         -0.0781, -0.0792,  0.0319, -0.0498,  0.0292],\n",
      "        [ 0.0171, -0.0202,  0.0379,  0.0372,  0.0546,  0.0875,  0.0669, -0.0267,\n",
      "         -0.0629,  0.0106,  0.0300,  0.0100,  0.0423, -0.0578, -0.0515, -0.0605,\n",
      "         -0.0799, -0.0526, -0.0196,  0.0944,  0.0218, -0.0206, -0.0409,  0.0014,\n",
      "          0.0031,  0.0794, -0.0897, -0.0527, -0.0252, -0.0295,  0.0016,  0.0606,\n",
      "         -0.0670, -0.0507, -0.0682, -0.0997,  0.0489,  0.0173, -0.0074,  0.0540,\n",
      "         -0.0142, -0.0430,  0.0623, -0.0776, -0.0119,  0.1037, -0.0486,  0.0331,\n",
      "         -0.0588,  0.0139, -0.0882, -0.0142,  0.0500, -0.0190, -0.0245,  0.0081,\n",
      "         -0.0689, -0.0604,  0.0097, -0.0391, -0.0466,  0.0268, -0.0771,  0.0845,\n",
      "          0.0130,  0.0609, -0.0879, -0.0069, -0.0455, -0.0508, -0.0895, -0.0159,\n",
      "          0.0716, -0.0754,  0.1017,  0.0391, -0.0179, -0.0062,  0.0032, -0.0084,\n",
      "          0.0888, -0.0001,  0.0530, -0.0301, -0.0914, -0.0100, -0.0075, -0.0774,\n",
      "          0.0291,  0.0449, -0.0033,  0.0312,  0.1022],\n",
      "        [-0.0135, -0.0622,  0.0067,  0.0204, -0.0003, -0.0479, -0.0668, -0.0594,\n",
      "          0.0668, -0.0240, -0.0355, -0.0270, -0.1008, -0.0839,  0.0140,  0.0417,\n",
      "         -0.0353,  0.0795, -0.0200,  0.0345,  0.0112,  0.0481, -0.0085,  0.0207,\n",
      "         -0.0863,  0.0282,  0.0901, -0.0003,  0.0473,  0.0773,  0.0093, -0.0106,\n",
      "          0.0389,  0.0002, -0.0294,  0.0872,  0.0308, -0.0315,  0.0109, -0.0812,\n",
      "          0.0676,  0.0612, -0.0288, -0.0071, -0.0956,  0.0731, -0.0734,  0.0146,\n",
      "          0.0433, -0.0881, -0.0818, -0.0407,  0.0675, -0.0109, -0.0639, -0.0344,\n",
      "          0.0683, -0.0800, -0.0478,  0.0220, -0.0827,  0.0722, -0.0956,  0.1002,\n",
      "         -0.0024,  0.0468, -0.0581, -0.0188,  0.0059,  0.0217, -0.0285,  0.0599,\n",
      "         -0.0369,  0.0268, -0.0942, -0.0460, -0.0572, -0.0369,  0.0943, -0.0434,\n",
      "         -0.0623,  0.0640, -0.0329, -0.0909,  0.0734,  0.0537, -0.0536,  0.0677,\n",
      "         -0.0374,  0.0661, -0.0532, -0.0171,  0.0599],\n",
      "        [-0.0750,  0.0295,  0.0226, -0.0413, -0.0483, -0.0186, -0.0165, -0.0368,\n",
      "          0.0183,  0.0260,  0.0272, -0.0907, -0.0569,  0.0686,  0.0315, -0.0870,\n",
      "         -0.0297,  0.0464, -0.0382,  0.0017,  0.0699, -0.0235,  0.0954,  0.0807,\n",
      "         -0.0855,  0.0675,  0.0467,  0.0979, -0.0999,  0.0483, -0.0100,  0.0610,\n",
      "          0.0745, -0.0317, -0.0326, -0.0105,  0.0413,  0.0945,  0.0358,  0.0581,\n",
      "         -0.0562,  0.0949, -0.0737,  0.0256,  0.0035, -0.0816,  0.0291,  0.0155,\n",
      "          0.0963, -0.0603,  0.0464, -0.0390,  0.0408, -0.0735, -0.0743,  0.0648,\n",
      "         -0.0631, -0.0385, -0.0426,  0.0042,  0.0489,  0.1030, -0.0293,  0.0507,\n",
      "         -0.0765, -0.0265,  0.0730, -0.0401,  0.0902, -0.0201,  0.0326, -0.0501,\n",
      "          0.0176,  0.0828,  0.0431,  0.0251, -0.0294, -0.0875, -0.0691,  0.0422,\n",
      "          0.0756,  0.0451,  0.0727,  0.0964,  0.0704, -0.1020,  0.0228,  0.0744,\n",
      "          0.0306,  0.0986, -0.0602, -0.0712, -0.0725],\n",
      "        [ 0.0264, -0.0729,  0.0353,  0.0099, -0.0581,  0.0773,  0.0661,  0.0119,\n",
      "          0.0387, -0.0823,  0.1012, -0.0256, -0.0611, -0.0919,  0.0661, -0.0229,\n",
      "          0.0616,  0.0853,  0.0568, -0.0821, -0.0396,  0.0383, -0.0954, -0.0074,\n",
      "          0.0682,  0.0013, -0.0422,  0.0635, -0.0924,  0.0655,  0.0202, -0.0568,\n",
      "          0.0544,  0.0007, -0.0408,  0.0957,  0.0737,  0.0407,  0.0048, -0.0264,\n",
      "          0.1009, -0.0334, -0.0980, -0.0522,  0.0528,  0.0822,  0.0384, -0.0046,\n",
      "          0.0886,  0.0186, -0.0225,  0.0362, -0.0916,  0.0901, -0.0423,  0.0625,\n",
      "         -0.0980,  0.0905, -0.0117, -0.0426, -0.0157,  0.0104, -0.0303, -0.0790,\n",
      "          0.0337,  0.0408,  0.0635, -0.0154,  0.0180, -0.0731,  0.0575, -0.0791,\n",
      "          0.0618,  0.0777, -0.0997, -0.0118,  0.0198,  0.0857,  0.0909,  0.0991,\n",
      "          0.0596,  0.0646,  0.0825,  0.0672,  0.1027,  0.0675,  0.0675,  0.0668,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         -0.0694, -0.0446,  0.1007,  0.0957, -0.0885]], requires_grad=True)\n",
      "\n",
      "edge_embed_lin1.bias Parameter containing:\n",
      "tensor([ 0.0608, -0.0800,  0.0141,  0.0323,  0.0566, -0.0966, -0.0722,  0.0135,\n",
      "        -0.0744, -0.0802], requires_grad=True)\n",
      "\n",
      "node_update_conv_nn_1.0.weight Parameter containing:\n",
      "tensor([[-0.1082, -0.2229,  0.2238, -0.0007,  0.2075, -0.1157, -0.2121,  0.0803,\n",
      "         -0.1268, -0.0420]], requires_grad=True)\n",
      "\n",
      "node_update_conv_nn_1.0.bias Parameter containing:\n",
      "tensor([-0.0403], requires_grad=True)\n",
      "\n",
      "node_update_conv_nn_1.1.weight Parameter containing:\n",
      "tensor([1.], requires_grad=True)\n",
      "\n",
      "node_update_conv_nn_1.1.bias Parameter containing:\n",
      "tensor([0.], requires_grad=True)\n",
      "\n",
      "node_update_conv_1.root Parameter containing:\n",
      "tensor([[0.6959]], requires_grad=True)\n",
      "\n",
      "node_update_conv_1.bias Parameter containing:\n",
      "tensor([0.3190], requires_grad=True)\n",
      "\n",
      "node_update_conv_nn_2.0.weight Parameter containing:\n",
      "tensor([[-0.2726,  0.1703,  0.1378, -0.0291, -0.0169,  0.2576, -0.0748, -0.2994,\n",
      "          0.1684, -0.0516]], requires_grad=True)\n",
      "\n",
      "node_update_conv_nn_2.0.bias Parameter containing:\n",
      "tensor([-0.2545], requires_grad=True)\n",
      "\n",
      "node_update_conv_nn_2.1.weight Parameter containing:\n",
      "tensor([1.], requires_grad=True)\n",
      "\n",
      "node_update_conv_nn_2.1.bias Parameter containing:\n",
      "tensor([0.], requires_grad=True)\n",
      "\n",
      "node_update_conv_2.root Parameter containing:\n",
      "tensor([[-0.9407]], requires_grad=True)\n",
      "\n",
      "node_update_conv_2.bias Parameter containing:\n",
      "tensor([0.6934], requires_grad=True)\n",
      "\n",
      "node_update_conv_nn_3.0.weight Parameter containing:\n",
      "tensor([[ 0.2016, -0.0971, -0.0902,  0.2413,  0.2776,  0.0445, -0.2309,  0.1828,\n",
      "         -0.0754,  0.1773]], requires_grad=True)\n",
      "\n",
      "node_update_conv_nn_3.0.bias Parameter containing:\n",
      "tensor([0.3032], requires_grad=True)\n",
      "\n",
      "node_update_conv_nn_3.1.weight Parameter containing:\n",
      "tensor([1.], requires_grad=True)\n",
      "\n",
      "node_update_conv_nn_3.1.bias Parameter containing:\n",
      "tensor([0.], requires_grad=True)\n",
      "\n",
      "node_update_conv_3.root Parameter containing:\n",
      "tensor([[0.6776]], requires_grad=True)\n",
      "\n",
      "node_update_conv_3.bias Parameter containing:\n",
      "tensor([-0.4865], requires_grad=True)\n",
      "\n",
      "edge_update_conv_1.edge_mlp.0.weight Parameter containing:\n",
      "tensor([[ 0.0734, -0.2799,  0.2030,  0.0991, -0.2209, -0.0788, -0.1209,  0.1730,\n",
      "         -0.2867, -0.1797, -0.0761, -0.1768],\n",
      "        [-0.0330, -0.1175, -0.1611,  0.0981,  0.0216,  0.2145, -0.2498, -0.0520,\n",
      "         -0.0993,  0.2577,  0.1162,  0.0748],\n",
      "        [ 0.0233, -0.1511,  0.2664,  0.1954, -0.2638, -0.2038,  0.1297,  0.0123,\n",
      "         -0.1167,  0.2675,  0.1072,  0.1348],\n",
      "        [ 0.0624,  0.2008,  0.2728, -0.1985,  0.0137,  0.2134, -0.1474,  0.0271,\n",
      "         -0.1269,  0.1860,  0.2835, -0.1529],\n",
      "        [ 0.1339,  0.0029, -0.0739,  0.0009,  0.2872,  0.1030,  0.0465, -0.1702,\n",
      "          0.0619, -0.1861,  0.1075,  0.0581],\n",
      "        [-0.2271,  0.0480,  0.0601,  0.0911,  0.0874,  0.1892, -0.2865,  0.1231,\n",
      "         -0.2032, -0.1333, -0.2744,  0.2189],\n",
      "        [-0.0316, -0.1056,  0.0017, -0.2198, -0.1266, -0.1978,  0.2285,  0.2608,\n",
      "         -0.2272, -0.2342, -0.0065,  0.1919],\n",
      "        [ 0.1254, -0.0049, -0.0745,  0.2546,  0.2388, -0.0866, -0.0425,  0.0124,\n",
      "         -0.2170,  0.1993, -0.2308,  0.2866],\n",
      "        [-0.1447, -0.1487, -0.2286,  0.1709, -0.2083, -0.1823, -0.2814,  0.0375,\n",
      "         -0.1486,  0.2383,  0.0040, -0.1521],\n",
      "        [ 0.1004,  0.0577, -0.2044,  0.2086,  0.2299, -0.1456,  0.2442,  0.1929,\n",
      "          0.2438, -0.1014,  0.0884, -0.1253]], requires_grad=True)\n",
      "\n",
      "edge_update_conv_1.edge_mlp.0.bias Parameter containing:\n",
      "tensor([-0.0155,  0.2222, -0.0783, -0.1050,  0.2664, -0.2274, -0.1254,  0.0863,\n",
      "         0.1457, -0.2504], requires_grad=True)\n",
      "\n",
      "edge_update_conv_2.edge_mlp.0.weight Parameter containing:\n",
      "tensor([[-0.2556,  0.0469,  0.0411, -0.2363, -0.2173, -0.0387, -0.2084,  0.2405,\n",
      "         -0.0765, -0.2151,  0.1777, -0.2842],\n",
      "        [-0.2818,  0.2380, -0.1306,  0.0380, -0.1952,  0.1968, -0.1760,  0.1654,\n",
      "          0.0268, -0.0423,  0.1806, -0.1401],\n",
      "        [-0.1079, -0.1271,  0.1690,  0.1437,  0.0602, -0.1330,  0.2498,  0.0920,\n",
      "          0.1094, -0.2360,  0.0458, -0.1776],\n",
      "        [ 0.0018, -0.2231, -0.2499,  0.2551,  0.1045, -0.0427,  0.2271,  0.2554,\n",
      "          0.1239,  0.2142, -0.2128, -0.1630],\n",
      "        [ 0.1273, -0.2486, -0.2584,  0.1665,  0.2518, -0.1045,  0.0093, -0.0444,\n",
      "         -0.2241,  0.2597,  0.0068,  0.2158],\n",
      "        [ 0.0131,  0.1713, -0.0713,  0.1480,  0.0368,  0.2203, -0.0462,  0.1905,\n",
      "         -0.0854,  0.0043, -0.2617, -0.0443],\n",
      "        [ 0.0628,  0.2379,  0.0023, -0.1832,  0.0583, -0.0930,  0.2681, -0.1490,\n",
      "          0.0502,  0.1510,  0.2237,  0.1820],\n",
      "        [ 0.0257, -0.1224, -0.0986, -0.1375,  0.2810, -0.2089, -0.0172,  0.1058,\n",
      "         -0.0697, -0.1024,  0.0146,  0.0340],\n",
      "        [ 0.1093,  0.1994, -0.0702, -0.0649, -0.1783,  0.1408, -0.2640, -0.2756,\n",
      "         -0.1907,  0.2488, -0.0928,  0.1597],\n",
      "        [ 0.0455, -0.1166,  0.2690,  0.0273, -0.1783,  0.1513,  0.1397, -0.1908,\n",
      "          0.2195, -0.1966, -0.1701, -0.2687]], requires_grad=True)\n",
      "\n",
      "edge_update_conv_2.edge_mlp.0.bias Parameter containing:\n",
      "tensor([-0.1617,  0.0352, -0.1525, -0.2275,  0.0435, -0.0523, -0.0993,  0.0217,\n",
      "         0.0751,  0.2659], requires_grad=True)\n",
      "\n",
      "edge_update_conv_3.edge_mlp.0.weight Parameter containing:\n",
      "tensor([[-0.2073,  0.1288, -0.0443, -0.1750,  0.2652, -0.1408,  0.0530,  0.2244,\n",
      "         -0.1342,  0.0552,  0.0155, -0.2562],\n",
      "        [ 0.0268, -0.1085, -0.1269,  0.1411, -0.0305,  0.0800, -0.2834, -0.1498,\n",
      "         -0.2303, -0.0246,  0.1921, -0.0616],\n",
      "        [-0.1670,  0.2414, -0.1561,  0.0891, -0.2134, -0.2096,  0.1845,  0.0700,\n",
      "          0.2726,  0.2090,  0.1186,  0.0638],\n",
      "        [-0.1606,  0.1476, -0.0661,  0.1123, -0.0762,  0.1125, -0.2554,  0.0651,\n",
      "          0.0755,  0.2130, -0.0033, -0.0584],\n",
      "        [-0.2750, -0.1634,  0.1342,  0.2691,  0.2180, -0.1559,  0.1485, -0.0725,\n",
      "          0.0931, -0.1285,  0.1478,  0.1707],\n",
      "        [-0.1552, -0.0752, -0.1887,  0.1352, -0.0254, -0.2015,  0.0780,  0.2022,\n",
      "          0.2447,  0.0151, -0.0781,  0.1788],\n",
      "        [ 0.2779, -0.1443,  0.1119,  0.1166, -0.0492, -0.0334, -0.1773,  0.1513,\n",
      "          0.2760,  0.1250, -0.1178, -0.1719],\n",
      "        [ 0.0157, -0.0943,  0.1238, -0.2151,  0.2846,  0.2360, -0.1952,  0.0238,\n",
      "          0.1953,  0.1579, -0.1897, -0.0314],\n",
      "        [ 0.2819,  0.1219, -0.2818, -0.2019,  0.2135, -0.2680,  0.1041, -0.2024,\n",
      "         -0.0962,  0.1429,  0.1269,  0.1447],\n",
      "        [ 0.1233, -0.2559,  0.2841, -0.1324, -0.1329,  0.1095,  0.2059,  0.0758,\n",
      "          0.0234, -0.1813,  0.1064, -0.1248]], requires_grad=True)\n",
      "\n",
      "edge_update_conv_3.edge_mlp.0.bias Parameter containing:\n",
      "tensor([-0.1675, -0.2785,  0.1582, -0.1211,  0.1381, -0.0288,  0.1178,  0.1013,\n",
      "        -0.1214, -0.0754], requires_grad=True)\n",
      "\n",
      "edge_class_lin1.weight Parameter containing:\n",
      "tensor([[ 0.0321, -0.2817,  0.2063, -0.2467, -0.2074,  0.1022, -0.0286,  0.0433,\n",
      "         -0.1922,  0.0965],\n",
      "        [-0.2455, -0.0621, -0.1636,  0.0948, -0.1214,  0.1431, -0.0560,  0.2918,\n",
      "          0.1855,  0.0272]], requires_grad=True)\n",
      "\n",
      "edge_class_lin1.bias Parameter containing:\n",
      "tensor([0.0566, 0.0520], requires_grad=True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Net(node_features, edge_features)\n",
    "model.named_parameters\n",
    "for n, p in model.named_parameters():\n",
    "    print(n, p)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andy.knapper\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 1 GPU(s)!\n",
      "loss at iteration  0  is  tensor(0.7629, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  1  is  tensor(0.3376, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  2  is  tensor(0.0455, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  3  is  tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  4  is  tensor(9.9314e-06, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  5  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  6  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  7  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  8  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  9  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  10  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  11  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  12  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  13  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  14  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  15  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  16  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  17  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  18  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  19  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  20  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  21  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  22  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  23  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  24  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  25  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  26  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  27  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  28  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  29  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  30  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  31  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  32  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  33  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  34  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  35  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  36  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  37  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  38  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  39  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  40  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  41  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  42  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  43  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  44  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  45  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  46  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  47  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  48  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  49  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  50  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  51  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  52  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  53  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  54  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  55  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  56  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  57  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  58  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  59  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  60  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss at iteration  61  is  tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-365-d97349421881>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbtch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m#         print(torch.sum(btch.edge_attr))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-362-eca56733a604>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;31m#         #update the node attributes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode_update_conv_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m         \u001b[1;31m#update the edges attributes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medge_update_conv_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch_geometric\\nn\\conv\\nn_conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0mpseudo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpseudo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpseudo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_j\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpseudo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py\u001b[0m in \u001b[0;36mpropagate\u001b[1;34m(self, edge_index, size, dim, **kwargs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmessage_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscatter_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maggr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mupdate_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch_geometric\\nn\\conv\\nn_conv.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, aggr_out, x)\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maggr_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m             \u001b[0maggr_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maggr_out\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[0maggr_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maggr_out\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Net(node_features, edge_features)\n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "print('Let\\'s use', torch.cuda.device_count(), 'GPU(s)!')\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "data_list = [graph_constructors.make_pyg_graph(*np.array(synthetic_data.make_a_group())).to(device) for _ in range(1)]\n",
    "loader = DataLoader(data_list, batch_size=1)\n",
    "\n",
    "for j in range(500):\n",
    "    \n",
    "    for i, btch in enumerate(loader):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(btch)\n",
    "\n",
    "#         print(torch.sum(btch.edge_attr))\n",
    "        \n",
    "#         y = btch.y_bi.to(output.device)\n",
    "        y = btch.y.to(output.device)\n",
    "        \n",
    "#         print(y)\n",
    "        \n",
    "        loss = F.nll_loss(output, y)\n",
    "        loss.backward()\n",
    "#         if i % 100 == 0:\n",
    "#             plot_grad_flow(model.named_parameters())\n",
    "        optimizer.step()\n",
    "    \n",
    "    print('loss at iteration ', j ,' is ', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andy.knapper\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 1 GPU(s)!\n",
      "loss at iteration  0  is  tensor(0.6931, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-371-2a7e646d7155>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m#print(j)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mdata_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mgraph_constructors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_pyg_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msynthetic_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_a_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-371-2a7e646d7155>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m#print(j)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mdata_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mgraph_constructors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_pyg_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msynthetic_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_a_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch_geometric\\data\\data.py\u001b[0m in \u001b[0;36mto\u001b[1;34m(self, device, *keys)\u001b[0m\n\u001b[0;32m    274\u001b[0m         \u001b[0mIf\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgiven\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mconversion\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mapplied\u001b[0m \u001b[0mto\u001b[0m \u001b[0mall\u001b[0m \u001b[0mpresent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m         attributes.\"\"\"\n\u001b[1;32m--> 276\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch_geometric\\data\\data.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, *keys)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch_geometric\\data\\data.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    274\u001b[0m         \u001b[0mIf\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgiven\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mconversion\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mapplied\u001b[0m \u001b[0mto\u001b[0m \u001b[0mall\u001b[0m \u001b[0mpresent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m         attributes.\"\"\"\n\u001b[1;32m--> 276\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Net(node_features, edge_features)\n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "print('Let\\'s use', torch.cuda.device_count(), 'GPU(s)!')\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for j in range(1000):\n",
    "    \n",
    "    #print(j)\n",
    "    \n",
    "    data_list = [graph_constructors.make_pyg_graph(*np.array(synthetic_data.make_a_group())).to(device) for _ in range(1024)]\n",
    "    loader = DataLoader(data_list, batch_size=8)\n",
    "\n",
    "    for i, btch in enumerate(loader):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(btch)\n",
    "\n",
    "        y = btch.y.to(output.device)\n",
    "        loss = F.nll_loss(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print('loss at iteration ', j ,' is ', loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try something new - RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to create a network that identifies regular vs. irregular components by passing through a bi-directional GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [graph_constructors.make_pyg_graph(*np.array(synthetic_data.make_a_group())).to(device) for _ in range(32)]\n",
    "loader = DataLoader(data_list, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0.        ,    7.        ,   14.        ,   21.        ,\n",
       "          28.        ,   35.        ,   42.        ,   49.        ,\n",
       "          56.        ,   63.        ,   70.        ,   77.        ,\n",
       "          84.        ,   91.        ,   98.        ,  112.        ,\n",
       "          43.        ,   38.        ,   80.        ,  106.        ],\n",
       "       [-149.69888217, -144.67759909, -146.62353463, -152.1454524 ,\n",
       "        -147.33202854, -150.84649004, -176.95915343, -184.81938074,\n",
       "        -179.30710214, -178.11290727, -181.45039341, -178.77139133,\n",
       "        -177.13903773, -180.80335917, -180.212116  , -177.89491905,\n",
       "        -750.5930489 , -604.96421672, -611.11670711, -471.94526902],\n",
       "       [   0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           1.        ,    1.        ,    1.        ,    1.        ]])"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(synthetic_data.make_a_group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 3, 2, 2, 6, 0, 6, 3,\n",
       "       1, 0, 2, 4, 5, 6, 1, 6], dtype=int32)"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day_of_the_week = np.mod(d_arr,7)\n",
    "day_of_the_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 111,\n",
       " 1110,\n",
       " 11100,\n",
       " 100011,\n",
       " 101010,\n",
       " 110001,\n",
       " 111000,\n",
       " 111111,\n",
       " 1000110,\n",
       " 1001101,\n",
       " 1010100,\n",
       " 1011011,\n",
       " 1100010,\n",
       " 11011,\n",
       " 111011,\n",
       " 1000001,\n",
       " 1001,\n",
       " 1011010,\n",
       " 11100,\n",
       " 100010,\n",
       " 1001001,\n",
       " 111001,\n",
       " 1001101,\n",
       " 11110,\n",
       " 11001,\n",
       " 100001,\n",
       " 111110,\n",
       " 11101,\n",
       " 110000]"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bin = lambda x: format(x, 'b')\n",
    "[int(get_bin(x)) for x in d_arr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try something new - pixel CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [graph_constructors.make_pyg_graph(*np.array(synthetic_data.make_a_group())).to(device) for _ in range(32)]\n",
    "loader = DataLoader(data_list, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_lst = 0\n",
    "for _ in range(1000):\n",
    "    d_lst, a_lst, g_lst = synthetic_data.make_a_group()\n",
    "    max_lst = max(max_lst, max(d_lst))\n",
    "max_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1291.8204799422456"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_lst = 0\n",
    "for _ in range(1000):\n",
    "    d_lst, a_lst, g_lst = synthetic_data.make_a_group()\n",
    "    min_lst = min(min_lst, min(a_lst))\n",
    "min_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_trans = len(a_arr)\n",
    "num_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.random.randint(0,30)\n",
    "d_arr[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pixel_centred_d_arr(inp_d_arr, inp_a_arr, idx):\n",
    "    #find transactions within 100 days either side of this transaction\n",
    "    date_mask = np.logical_and(inp_d_arr[idx]-100 <= inp_d_arr, inp_d_arr <= inp_d_arr[idx]+100)\n",
    "    return inp_d_arr[date_mask]-inp_d_arr[idx]+100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pixel_centred_a_arr(inp_d_arr, inp_a_arr, idx):\n",
    "    date_mask = np.logical_and(inp_d_arr[idx]-100 <= inp_d_arr, inp_d_arr <= inp_d_arr[idx]+100)\n",
    "    raw_a = inp_a_arr[date_mask]-inp_a_arr[idx]\n",
    "    scaler = max(abs(np.min(raw_a)),abs(np.max(raw_a)))\n",
    "    return np.round(100+raw_a*100/scaler,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colour_list = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan']\n",
    "\n",
    "for i in range(2):\n",
    "    d_lst, a_lst, g_lst = synthetic_data.make_a_group()\n",
    "    \n",
    "    d_arr = np.array(d_lst)\n",
    "    a_arr = np.array(a_lst)\n",
    "    g_arr = np.array(g_lst)    \n",
    "    \n",
    "    num_trans = len(a_arr)\n",
    "    idx = np.random.randint(0,num_trans)\n",
    "    \n",
    "#     print(num_trans, idx)\n",
    "    \n",
    "    pixel_centred_d_arr = find_pixel_centred_d_arr(d_arr, a_arr, idx)\n",
    "    pixel_centred_a_arr = find_pixel_centred_a_arr(d_arr, a_arr, idx)\n",
    "    pixel_centred_g_arr = np.repeat(0, len(pixel_centred_a_arr))\n",
    "    \n",
    "#     print(len(pixel_centred_d_arr))\n",
    "#     print(len(pixel_centred_a_arr))\n",
    "    \n",
    "    fig, (ax1) = plt.subplots(nrows=1, ncols=1, figsize=(10,8), sharex=True)\n",
    "    ax1.scatter(pixel_centred_d_arr, pixel_centred_a_arr, s=10, marker='x')\n",
    "    ax1.set_title(str(i))\n",
    "    ax1.set_xlim([0,200])\n",
    "    ax1.set_ylim([0,200])\n",
    "\n",
    "    \n",
    "    for ax1 in fig.axes:\n",
    "        matplotlib.pyplot.sca(ax1)\n",
    "        plt.xticks(rotation=90)\n",
    "        #plt.legend(bbox_to_anchor=(1.02, 1), loc=2, borderaxespad=0.)\n",
    "    \n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
