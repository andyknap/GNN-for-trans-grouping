{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Unet CNN Pixel classification model for grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch_geometric'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f712ca5a1220>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch_geometric'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import timeit\n",
    "import statistics\n",
    "import time\n",
    "import torch\n",
    "import torch_geometric\n",
    "import importlib\n",
    "\n",
    "from data_utils import synthetic_data\n",
    "from data_utils import graph_constructors\n",
    "from data_utils import group_to_image_constructors\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import importlib\n",
    "\n",
    "from Unet import helper\n",
    "from Unet import simulation\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data_utils.group_to_image_constructors' from 'C:\\\\Users\\\\andy.knapper\\\\Documents\\\\OW\\\\Categorisation\\\\ML grouping\\\\GNN-for-trans-grouping\\\\data_utils\\\\group_to_image_constructors.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(synthetic_data)\n",
    "importlib.reload(graph_constructors)\n",
    "importlib.reload(group_to_image_constructors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colour_list = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan']\n",
    "\n",
    "for i in range(2):\n",
    "    d_lst, a_lst, g_lst, t_lst = synthetic_data.make_a_group()\n",
    "    \n",
    "    d_arr = np.array(d_lst)\n",
    "    a_arr = np.array(a_lst)\n",
    "    g_arr = np.array(g_lst)    \n",
    "    \n",
    "    fig, (ax1) = plt.subplots(nrows=1, ncols=1, figsize=(10,8), sharex=True)\n",
    "    for g in g_lst:\n",
    "        mask = (g_arr == g)\n",
    "        \n",
    "        ax1.scatter(d_arr[mask], a_arr[mask], s=10, c=colour_list[g%10], marker='x')\n",
    "        ax1.set_title(str(i))\n",
    "        #ax1.legend(loc=\"upper right\")\n",
    "    \n",
    "    for ax1 in fig.axes:\n",
    "        matplotlib.pyplot.sca(ax1)\n",
    "        plt.xticks(rotation=90)\n",
    "        #plt.legend(bbox_to_anchor=(1.02, 1), loc=2, borderaxespad=0.)\n",
    "    \n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_lst, a_lst, g_lst = synthetic_data.make_a_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_arr = np.array(d_lst)\n",
    "a_arr = np.array(a_lst)\n",
    "g_arr = np.array(g_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_a_arr = graph_constructors.normalise_amounts(a_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unet demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 192, 192, 3)\n",
      "0 255\n",
      "(3, 6, 192, 192)\n",
      "0.0 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x864 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Generate some random images\n",
    "input_images, target_masks = simulation.generate_random_data(192, 192, count=3)\n",
    "\n",
    "for x in [input_images, target_masks]:\n",
    "    print(x.shape)\n",
    "    print(x.min(), x.max())\n",
    "\n",
    "# Change channel-order and make 3 channels for matplot\n",
    "input_images_rgb = [x.astype(np.uint8) for x in input_images]\n",
    "\n",
    "# Map each channel (i.e. class) to each color\n",
    "target_masks_rgb = [helper.masks_to_colorimg(x) for x in target_masks]\n",
    "\n",
    "# Left: Input image (black and white), Right: Target mask (6ch)\n",
    "helper.plot_side_by_side([input_images_rgb, target_masks_rgb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "\n",
    "class SimDataset(Dataset):\n",
    "    def __init__(self, count, transform=None):\n",
    "        self.input_images, self.target_masks = simulation.generate_random_data(192, 192, count=count)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.input_images[idx]\n",
    "        mask = self.target_masks[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return [image, mask]\n",
    "\n",
    "# use the same transformations for train/val in this example\n",
    "trans = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # imagenet\n",
    "])\n",
    "\n",
    "train_set = SimDataset(2000, transform = trans)\n",
    "val_set = SimDataset(200, transform = trans)\n",
    "\n",
    "image_datasets = {\n",
    "    'train': train_set, 'val': val_set\n",
    "}\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "dataloaders_orig = {\n",
    "    'train': DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0),\n",
    "    'val': DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "192/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders_orig['train'].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders_orig['train'].dataset.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders_orig['train'].dataset.input_images.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders_orig['val'].dataset.input_images.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders_orig['val'].dataset.input_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders_orig['val'].dataset.target_masks.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### my dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "\n",
    "class SimDataset(Dataset):\n",
    "    def __init__(self, count, transform=None):\n",
    "        self.sim_data = [group_to_image_constructors.make_an_image(*np.array(synthetic_data.make_a_group())) for _ in range(count)]\n",
    "        self.input_images = np.array([x[0] for  x in self.sim_data]).astype('uint8')\n",
    "        self.target_masks = np.array([x[1] for  x in self.sim_data]).astype('float32')\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.input_images[idx]\n",
    "        mask = self.target_masks[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return [image, mask]\n",
    "\n",
    "# use the same transformations for train/val in this example\n",
    "trans = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # imagenet\n",
    "])\n",
    "\n",
    "train_set = SimDataset(2000, transform = trans)\n",
    "val_set = SimDataset(200, transform = trans)\n",
    "\n",
    "image_datasets = {\n",
    "    'train': train_set, 'val': val_set\n",
    "}\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0),\n",
    "    'val': DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 224, 224]) torch.Size([4, 2, 224, 224])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x218272b2f88>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torchvision.utils\n",
    "\n",
    "def reverse_transform(inp):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    inp = (inp * 255).astype(np.uint8)\n",
    "\n",
    "    return inp\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, masks = next(iter(dataloaders['train']))\n",
    "\n",
    "print(inputs.shape, masks.shape)\n",
    "\n",
    "plt.imshow(reverse_transform(inputs[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "def convrelu(in_channels, out_channels, kernel, padding):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel, padding=padding),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "\n",
    "\n",
    "class ResNetUNet(nn.Module):\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__()\n",
    "\n",
    "        self.base_model = models.resnet18(pretrained=True)\n",
    "        self.base_layers = list(self.base_model.children())\n",
    "\n",
    "        self.layer0 = nn.Sequential(*self.base_layers[:3]) # size=(N, 64, x.H/2, x.W/2)\n",
    "        self.layer0_1x1 = convrelu(64, 64, 1, 0)\n",
    "        self.layer1 = nn.Sequential(*self.base_layers[3:5]) # size=(N, 64, x.H/4, x.W/4)\n",
    "        self.layer1_1x1 = convrelu(64, 64, 1, 0)\n",
    "        self.layer2 = self.base_layers[5]  # size=(N, 128, x.H/8, x.W/8)\n",
    "        self.layer2_1x1 = convrelu(128, 128, 1, 0)\n",
    "        self.layer3 = self.base_layers[6]  # size=(N, 256, x.H/16, x.W/16)\n",
    "        self.layer3_1x1 = convrelu(256, 256, 1, 0)\n",
    "        self.layer4 = self.base_layers[7]  # size=(N, 512, x.H/32, x.W/32)\n",
    "        self.layer4_1x1 = convrelu(512, 512, 1, 0)\n",
    "\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "        self.conv_up3 = convrelu(256 + 512, 512, 3, 1)\n",
    "        self.conv_up2 = convrelu(128 + 512, 256, 3, 1)\n",
    "        self.conv_up1 = convrelu(64 + 256, 256, 3, 1)\n",
    "        self.conv_up0 = convrelu(64 + 256, 128, 3, 1)\n",
    "\n",
    "        self.conv_original_size0 = convrelu(3, 64, 3, 1)\n",
    "        self.conv_original_size1 = convrelu(64, 64, 3, 1)\n",
    "        self.conv_original_size2 = convrelu(64 + 128, 64, 3, 1)\n",
    "\n",
    "        self.conv_last = nn.Conv2d(64, n_class, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x_original = self.conv_original_size0(input)\n",
    "        x_original = self.conv_original_size1(x_original)\n",
    "\n",
    "        layer0 = self.layer0(input)\n",
    "        layer1 = self.layer1(layer0)\n",
    "        layer2 = self.layer2(layer1)\n",
    "        layer3 = self.layer3(layer2)\n",
    "        layer4 = self.layer4(layer3)\n",
    "\n",
    "        layer4 = self.layer4_1x1(layer4)\n",
    "        x = self.upsample(layer4)\n",
    "        layer3 = self.layer3_1x1(layer3)\n",
    "        x = torch.cat([x, layer3], dim=1)\n",
    "        x = self.conv_up3(x)\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        layer2 = self.layer2_1x1(layer2)\n",
    "        x = torch.cat([x, layer2], dim=1)\n",
    "        x = self.conv_up2(x)\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        layer1 = self.layer1_1x1(layer1)\n",
    "        x = torch.cat([x, layer1], dim=1)\n",
    "        x = self.conv_up1(x)\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        layer0 = self.layer0_1x1(layer0)\n",
    "        x = torch.cat([x, layer0], dim=1)\n",
    "        x = self.conv_up0(x)\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, x_original], dim=1)\n",
    "        x = self.conv_original_size2(x)\n",
    "\n",
    "        out = self.conv_last(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ResNetUNet(n_class=2)\n",
    "model = model.to(device)\n",
    "\n",
    "# check keras-like model summary using torchsummary\n",
    "# from torchsummary import summary\n",
    "# summary(model, input_size=(3, 224, 224))\n",
    "# summary(model, input_size=(3, 512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "from Unet.loss import dice_loss\n",
    "\n",
    "def calc_loss(pred, target, metrics, bce_weight=0.5):\n",
    "    bce = F.binary_cross_entropy_with_logits(pred, target)\n",
    "\n",
    "    pred = F.sigmoid(pred)\n",
    "    dice = dice_loss(pred, target)\n",
    "\n",
    "    loss = bce * bce_weight + dice * (1 - bce_weight)\n",
    "\n",
    "    metrics['bce'] += bce.data.cpu().numpy() * target.size(0)\n",
    "    metrics['dice'] += dice.data.cpu().numpy() * target.size(0)\n",
    "    metrics['loss'] += loss.data.cpu().numpy() * target.size(0)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def print_metrics(metrics, epoch_samples, phase):\n",
    "    outputs = []\n",
    "    for k in metrics.keys():\n",
    "        outputs.append(\"{}: {:4f}\".format(k, metrics[k] / epoch_samples))\n",
    "\n",
    "    print(\"{}: {}\".format(phase, \", \".join(outputs)))\n",
    "\n",
    "def train_model(model, optimizer, scheduler, num_epochs=25):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 1e10\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        since = time.time()\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    print(\"LR\", param_group['lr'])\n",
    "\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            metrics = defaultdict(float)\n",
    "            epoch_samples = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = calc_loss(outputs, labels, metrics)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                epoch_samples += inputs.size(0)\n",
    "\n",
    "            print_metrics(metrics, epoch_samples, phase)\n",
    "            epoch_loss = metrics['loss'] / epoch_samples\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                print(\"saving best model\")\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    print('Best val loss: {:4f}'.format(best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import copy\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "num_class = 2\n",
    "model = ResNetUNet(num_class).to(device)\n",
    "\n",
    "# freeze backbone layers\n",
    "#for l in model.base_layers:\n",
    "#    for param in l.parameters():\n",
    "#        param.requires_grad = False\n",
    "\n",
    "optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=30, gamma=0.1)\n",
    "\n",
    "model = train_model(model, optimizer_ft, exp_lr_scheduler, num_epochs=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://discuss.pytorch.org/t/save-and-load-model/6206/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, '/home/a/Documents/GNN-for-trans-grouping/GNN-for-trans-grouping/Unet_model_1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = torch.load('/home/a/Documents/GNN-for-trans-grouping/GNN-for-trans-grouping/Unet_model_1.pt')\n",
    "model = torch.load(r'C:\\Users\\andy.knapper\\Documents\\OW\\Categorisation\\ML grouping\\GNN-for-trans-grouping\\Unet_model_1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim_data = [group_to_image_constructors.make_an_image(*np.array(synthetic_data.make_a_group())) for _ in range(3)]\n",
    "# input_images = np.array([x[0] for  x in sim_data]).astype('uint8')\n",
    "# target_masks = np.array([x[1] for  x in sim_data]).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "# output = model(torch.tensor(test_img))\n",
    "# prediction = torch.argmax(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
      "              ReLU-2         [-1, 64, 224, 224]               0\n",
      "            Conv2d-3         [-1, 64, 224, 224]          36,928\n",
      "              ReLU-4         [-1, 64, 224, 224]               0\n",
      "            Conv2d-5         [-1, 64, 112, 112]           9,408\n",
      "            Conv2d-6         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-7         [-1, 64, 112, 112]             128\n",
      "       BatchNorm2d-8         [-1, 64, 112, 112]             128\n",
      "              ReLU-9         [-1, 64, 112, 112]               0\n",
      "             ReLU-10         [-1, 64, 112, 112]               0\n",
      "        MaxPool2d-11           [-1, 64, 56, 56]               0\n",
      "        MaxPool2d-12           [-1, 64, 56, 56]               0\n",
      "           Conv2d-13           [-1, 64, 56, 56]          36,864\n",
      "           Conv2d-14           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-15           [-1, 64, 56, 56]             128\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      "             ReLU-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19           [-1, 64, 56, 56]          36,864\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "      BatchNorm2d-22           [-1, 64, 56, 56]             128\n",
      "             ReLU-23           [-1, 64, 56, 56]               0\n",
      "             ReLU-24           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-25           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-26           [-1, 64, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          36,864\n",
      "           Conv2d-28           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-29           [-1, 64, 56, 56]             128\n",
      "      BatchNorm2d-30           [-1, 64, 56, 56]             128\n",
      "             ReLU-31           [-1, 64, 56, 56]               0\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "           Conv2d-33           [-1, 64, 56, 56]          36,864\n",
      "           Conv2d-34           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-35           [-1, 64, 56, 56]             128\n",
      "      BatchNorm2d-36           [-1, 64, 56, 56]             128\n",
      "             ReLU-37           [-1, 64, 56, 56]               0\n",
      "             ReLU-38           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-39           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-40           [-1, 64, 56, 56]               0\n",
      "           Conv2d-41          [-1, 128, 28, 28]          73,728\n",
      "           Conv2d-42          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-43          [-1, 128, 28, 28]             256\n",
      "      BatchNorm2d-44          [-1, 128, 28, 28]             256\n",
      "             ReLU-45          [-1, 128, 28, 28]               0\n",
      "             ReLU-46          [-1, 128, 28, 28]               0\n",
      "           Conv2d-47          [-1, 128, 28, 28]         147,456\n",
      "           Conv2d-48          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-49          [-1, 128, 28, 28]             256\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "           Conv2d-51          [-1, 128, 28, 28]           8,192\n",
      "           Conv2d-52          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "      BatchNorm2d-54          [-1, 128, 28, 28]             256\n",
      "             ReLU-55          [-1, 128, 28, 28]               0\n",
      "             ReLU-56          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-57          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-58          [-1, 128, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]         147,456\n",
      "           Conv2d-60          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-61          [-1, 128, 28, 28]             256\n",
      "      BatchNorm2d-62          [-1, 128, 28, 28]             256\n",
      "             ReLU-63          [-1, 128, 28, 28]               0\n",
      "             ReLU-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65          [-1, 128, 28, 28]         147,456\n",
      "           Conv2d-66          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-67          [-1, 128, 28, 28]             256\n",
      "      BatchNorm2d-68          [-1, 128, 28, 28]             256\n",
      "             ReLU-69          [-1, 128, 28, 28]               0\n",
      "             ReLU-70          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-71          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-72          [-1, 128, 28, 28]               0\n",
      "           Conv2d-73          [-1, 256, 14, 14]         294,912\n",
      "           Conv2d-74          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-75          [-1, 256, 14, 14]             512\n",
      "      BatchNorm2d-76          [-1, 256, 14, 14]             512\n",
      "             ReLU-77          [-1, 256, 14, 14]               0\n",
      "             ReLU-78          [-1, 256, 14, 14]               0\n",
      "           Conv2d-79          [-1, 256, 14, 14]         589,824\n",
      "           Conv2d-80          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-81          [-1, 256, 14, 14]             512\n",
      "      BatchNorm2d-82          [-1, 256, 14, 14]             512\n",
      "           Conv2d-83          [-1, 256, 14, 14]          32,768\n",
      "           Conv2d-84          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-85          [-1, 256, 14, 14]             512\n",
      "      BatchNorm2d-86          [-1, 256, 14, 14]             512\n",
      "             ReLU-87          [-1, 256, 14, 14]               0\n",
      "             ReLU-88          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-89          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-90          [-1, 256, 14, 14]               0\n",
      "           Conv2d-91          [-1, 256, 14, 14]         589,824\n",
      "           Conv2d-92          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-93          [-1, 256, 14, 14]             512\n",
      "      BatchNorm2d-94          [-1, 256, 14, 14]             512\n",
      "             ReLU-95          [-1, 256, 14, 14]               0\n",
      "             ReLU-96          [-1, 256, 14, 14]               0\n",
      "           Conv2d-97          [-1, 256, 14, 14]         589,824\n",
      "           Conv2d-98          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-99          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-100          [-1, 256, 14, 14]             512\n",
      "            ReLU-101          [-1, 256, 14, 14]               0\n",
      "            ReLU-102          [-1, 256, 14, 14]               0\n",
      "      BasicBlock-103          [-1, 256, 14, 14]               0\n",
      "      BasicBlock-104          [-1, 256, 14, 14]               0\n",
      "          Conv2d-105            [-1, 512, 7, 7]       1,179,648\n",
      "          Conv2d-106            [-1, 512, 7, 7]       1,179,648\n",
      "     BatchNorm2d-107            [-1, 512, 7, 7]           1,024\n",
      "     BatchNorm2d-108            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-109            [-1, 512, 7, 7]               0\n",
      "            ReLU-110            [-1, 512, 7, 7]               0\n",
      "          Conv2d-111            [-1, 512, 7, 7]       2,359,296\n",
      "          Conv2d-112            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-113            [-1, 512, 7, 7]           1,024\n",
      "     BatchNorm2d-114            [-1, 512, 7, 7]           1,024\n",
      "          Conv2d-115            [-1, 512, 7, 7]         131,072\n",
      "          Conv2d-116            [-1, 512, 7, 7]         131,072\n",
      "     BatchNorm2d-117            [-1, 512, 7, 7]           1,024\n",
      "     BatchNorm2d-118            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-119            [-1, 512, 7, 7]               0\n",
      "            ReLU-120            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-121            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-122            [-1, 512, 7, 7]               0\n",
      "          Conv2d-123            [-1, 512, 7, 7]       2,359,296\n",
      "          Conv2d-124            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-125            [-1, 512, 7, 7]           1,024\n",
      "     BatchNorm2d-126            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-127            [-1, 512, 7, 7]               0\n",
      "            ReLU-128            [-1, 512, 7, 7]               0\n",
      "          Conv2d-129            [-1, 512, 7, 7]       2,359,296\n",
      "          Conv2d-130            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-131            [-1, 512, 7, 7]           1,024\n",
      "     BatchNorm2d-132            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-133            [-1, 512, 7, 7]               0\n",
      "            ReLU-134            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-135            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-136            [-1, 512, 7, 7]               0\n",
      "          Conv2d-137            [-1, 512, 7, 7]         262,656\n",
      "            ReLU-138            [-1, 512, 7, 7]               0\n",
      "        Upsample-139          [-1, 512, 14, 14]               0\n",
      "          Conv2d-140          [-1, 256, 14, 14]          65,792\n",
      "            ReLU-141          [-1, 256, 14, 14]               0\n",
      "          Conv2d-142          [-1, 512, 14, 14]       3,539,456\n",
      "            ReLU-143          [-1, 512, 14, 14]               0\n",
      "        Upsample-144          [-1, 512, 28, 28]               0\n",
      "          Conv2d-145          [-1, 128, 28, 28]          16,512\n",
      "            ReLU-146          [-1, 128, 28, 28]               0\n",
      "          Conv2d-147          [-1, 256, 28, 28]       1,474,816\n",
      "            ReLU-148          [-1, 256, 28, 28]               0\n",
      "        Upsample-149          [-1, 256, 56, 56]               0\n",
      "          Conv2d-150           [-1, 64, 56, 56]           4,160\n",
      "            ReLU-151           [-1, 64, 56, 56]               0\n",
      "          Conv2d-152          [-1, 256, 56, 56]         737,536\n",
      "            ReLU-153          [-1, 256, 56, 56]               0\n",
      "        Upsample-154        [-1, 256, 112, 112]               0\n",
      "          Conv2d-155         [-1, 64, 112, 112]           4,160\n",
      "            ReLU-156         [-1, 64, 112, 112]               0\n",
      "          Conv2d-157        [-1, 128, 112, 112]         368,768\n",
      "            ReLU-158        [-1, 128, 112, 112]               0\n",
      "        Upsample-159        [-1, 128, 224, 224]               0\n",
      "          Conv2d-160         [-1, 64, 224, 224]         110,656\n",
      "            ReLU-161         [-1, 64, 224, 224]               0\n",
      "          Conv2d-162          [-1, 2, 224, 224]             130\n",
      "================================================================\n",
      "Total params: 28,976,386\n",
      "Trainable params: 28,976,386\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 416.12\n",
      "Params size (MB): 110.54\n",
      "Estimated Total Size (MB): 527.23\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = SimDataset(2, transform = trans)\n",
    "val_set = SimDataset(2, transform = trans)\n",
    "\n",
    "image_datasets = {\n",
    "    'train': train_set, 'val': val_set\n",
    "}\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0),\n",
    "    'val': DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.eval()\n",
    "for inputs, labels in dataloaders['train']:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.nn.functional.softmax(outputs, dim=1)\n",
    "p_arr = p.cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 1\n",
    "a_arr, d_arr = np.nonzero(np.max(reverse_transform(inputs[idx].cpu()), axis = 2))\n",
    "t_arr = (p_arr[idx, :, a_arr, d_arr][:,0]<0.5).astype(int)\n",
    "\n",
    "colour_list = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan']\n",
    "\n",
    "\n",
    "fig, (ax1) = plt.subplots(nrows=1, ncols=1, figsize=(10,8), sharex=True)\n",
    "for t in t_arr:\n",
    "    mask = (t_arr == t)\n",
    "    ax1.scatter(d_arr[mask], a_arr[mask], s=10, c=colour_list[t%10], marker='x')\n",
    "    \n",
    "for ax1 in fig.axes:\n",
    "    matplotlib.pyplot.sca(ax1)\n",
    "    plt.xticks(rotation=90)\n",
    "    #plt.legend(bbox_to_anchor=(1.02, 1), loc=2, borderaxespad=0.)\n",
    "    \n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
